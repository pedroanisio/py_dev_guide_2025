./validation.py
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Set, Any, Union, Type
from enum import Enum
import textwrap
import os
from pathlib import Path


class ModelType(Enum):
    """Types of Pydantic models"""
    DOMAIN = "Domain Model"
    DTO = "Data Transfer Object"
    SETTINGS = "Settings"
    REQUEST = "Request Model"
    RESPONSE = "Response Model"
    ERROR = "Error Model"


@dataclass
class PydanticModel:
    """Represents a Pydantic model definition"""
    name: str
    model_type: ModelType
    description: str
    code: str
    related_models: List[str] = field(default_factory=list)
    immutable: bool = True


@dataclass
class CorePrinciple:
    """Core principle for data validation"""
    name: str
    description: str
    example: Optional[str] = None


class ValidationPattern(Enum):
    """Common validation patterns"""
    FIELD_VALIDATOR = "Field Validator"
    MODEL_VALIDATOR = "Model Validator"
    ROOT_VALIDATOR = "Root Validator (v1 compatibility)"
    CONSTRAINT = "Field Constraint"
    TYPE_VALIDATION = "Type Validation"


@dataclass
class ToolingConfig:
    """Configuration for Pydantic-related tools"""
    tool: str
    config_snippet: str
    purpose: str


class DataValidationAndConfiguration:
    """
    Data Validation & Configuration
    
    A class representing best practices for using Pydantic for data validation
    and configuration management in Python applications.
    """
    
    def __init__(self):
        self.name = "Data Validation & Configuration"
        self.required_package = "pydantic"
        self.min_version = "2.0"
        
        # Core principles
        self.core_principles = [
            CorePrinciple(
                "Model Everything", 
                "Replace raw dict or typing.TypedDict at function/method boundaries and for internal state with Pydantic BaseModel subclasses.",
                """
# Instead of this:
def process_user(user_data: dict) -> dict:
    # Validation mixed with business logic
    if "email" not in user_data:
        raise ValueError("Email is required")
    # ...
    return {"id": 123, **user_data}

# Use this:
class UserInput(BaseModel):
    email: str
    name: str
    age: int | None = None

class UserOutput(BaseModel):
    id: int
    email: str
    name: str
    age: int | None = None

def process_user(user: UserInput) -> UserOutput:
    # Validation already handled by Pydantic
    # Business logic only
    return UserOutput(id=123, **user.model_dump())
"""
            ),
            CorePrinciple(
                "Configuration via Settings",
                "Centralize runtime configuration (environment variables, .env files, secrets) using a single Settings class inheriting from Pydantic's BaseSettings.",
                """
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        case_sensitive=False
    )
    
    debug: bool = False
    database_url: str
    api_key: str
"""
            ),
            CorePrinciple(
                "Immutability by Default",
                "Configure models as immutable (model_config = {'frozen': True}) unless there's a compelling reason for instances to be mutable.",
                """
class User(BaseModel):
    model_config = {"frozen": True}
    
    id: int
    name: str
    
# This will raise an error:
# user = User(id=1, name="Alice")
# user.name = "Bob"  # Error: instance is frozen
"""
            ),
            CorePrinciple(
                "Validate Early",
                "Construct Pydantic models as the first step when ingesting external data (e.g., from HTTP requests, CLI arguments, database rows).",
                """
def api_endpoint(request_data: dict):
    # Validate immediately at the boundary
    try:
        user_request = UserCreate(**request_data)
    except ValidationError as e:
        return {"error": e.errors()}
    
    # Now work with validated data
    process_user(user_request)
"""
            ),
            CorePrinciple(
                "Controlled Serialization",
                "Use Pydantic's built-in methods like .model_dump() and .model_dump_json() for generating outbound data payloads.",
                """
def get_user_response(user: User) -> dict:
    # Instead of manually creating a dict
    # return {"id": user.id, "name": user.name}
    
    # Use controlled serialization
    return user.model_dump(exclude={"password_hash"})
"""
            )
        ]
        
        # Folder structure recommendation
        self.recommended_layout = {
            "<root>/": {
                "src/": {
                    "<app_name>/": [
                        "__init__.py",
                        "models.py",  # Core domain models (internal representation)
                        "schemas.py", # Data transfer objects (API request/response models)
                        "config.py",  # Application settings management (Settings class)
                    ]
                }
            }
        }
        
        # Example models
        self.example_models = [
            PydanticModel(
                name="User",
                model_type=ModelType.DOMAIN,
                description="Basic domain model with field validation",
                code="""
from pydantic import BaseModel, Field, field_validator
from pydantic_core import PydanticCustomError

class User(BaseModel):
    model_config = {"frozen": True} # Immutable by default

    id: int = Field(..., gt=0, description="Unique user identifier")
    email: str
    is_active: bool = True

    @field_validator("email")
    @classmethod
    def email_must_contain_at_symbol(cls, v: str) -> str:
        if "@" not in v:
            # Use PydanticCustomError for specific error types
            raise PydanticCustomError(
                "value_error",
                "Email address must contain an '@' symbol",
                {"value": v}
            )
        return v.lower() # Example: Normalize email to lowercase
""",
                related_models=["Address", "UserProfile"]
            ),
            PydanticModel(
                name="Settings",
                model_type=ModelType.SETTINGS,
                description="Application settings with environment variable loading",
                code="""
import os
from functools import lru_cache
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field, PostgresDsn

class Settings(BaseSettings):
    # Define application settings, reading from environment variables
    model_config = SettingsConfigDict(
        env_file=".env",         # Load .env file if present
        case_sensitive=False,    # Environment variable names are case-insensitive
        extra="ignore"           # Ignore extra fields from environment
    )

    debug: bool = Field(default=False, description="Enable debug mode")
    # Example: Using a specific Pydantic type for validation
    database_url: PostgresDsn = Field(..., description="DSN for the primary database")
    # Example: Optional setting with default
    redis_url: str | None = Field(default=None, description="URL for Redis cache (optional)")

# Use lru_cache for efficient access to the settings singleton
@lru_cache()
def get_settings() -> Settings:
    """Returns the application settings instance."""
    # Settings automatically reads from environment variables / .env file on instantiation
    return Settings()
"""
            ),
            PydanticModel(
                name="Address",
                model_type=ModelType.DOMAIN,
                description="Nested model for use in relationships",
                code="""
from pydantic import BaseModel, Field

class Address(BaseModel):
    model_config = {"frozen": True}
    
    street: str
    city: str
    country: str
    postal_code: str
    is_primary: bool = False
""",
                related_models=["User"]
            ),
            PydanticModel(
                name="UserProfile",
                model_type=ModelType.DOMAIN,
                description="Related model with default values",
                code="""
from pydantic import BaseModel, Field
from typing import Optional, Dict

class UserProfile(BaseModel):
    bio: Optional[str] = None
    avatar_url: Optional[str] = None
    preferences: Dict[str, str] = Field(default_factory=dict)
""",
                related_models=["User"]
            ),
            PydanticModel(
                name="ErrorDetail",
                model_type=ModelType.ERROR,
                description="Error detail for API responses",
                code="""
from pydantic import BaseModel
from typing import List

class ErrorDetail(BaseModel):
    loc: List[str]  # Location of the error
    msg: str        # Error message
    type: str       # Error type
""",
                related_models=["ErrorResponse"]
            ),
            PydanticModel(
                name="ErrorResponse",
                model_type=ModelType.RESPONSE,
                description="Standardized error response for APIs",
                code="""
from pydantic import BaseModel
from typing import List
from .schemas import ErrorDetail

class ErrorResponse(BaseModel):
    detail: List[ErrorDetail]
""",
                related_models=["ErrorDetail"]
            )
        ]
        
        # Tooling config
        self.tooling_configs = [
            ToolingConfig(
                tool="mypy",
                config_snippet="""
[tool.mypy]
plugins = ["pydantic.mypy"]
follow_imports = "silent"
strict_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
disallow_any_generics = true
check_untyped_defs = true
no_implicit_reexport = true
disallow_untyped_defs = true
""",
                purpose="Enables static type checking correctness. The Pydantic Mypy plugin is crucial for validating model types, validators, and generic models."
            ),
            ToolingConfig(
                tool="ruff",
                config_snippet="""
[tool.ruff]
select = ["E", "F", "B", "I", "ARG", "PTH"]
ignore = []
line-length = 88
target-version = "py39"
""",
                purpose="Lints for general Python best practices, which often overlap with good Pydantic usage."
            )
        ]
        
        # Advanced patterns
        self.advanced_patterns = {
            "nested_models": """
from typing import List, Optional
from pydantic import BaseModel, Field, EmailStr, model_validator
from datetime import datetime
from uuid import UUID, uuid4

class Address(BaseModel):
    model_config = {"frozen": True}
    
    street: str
    city: str
    country: str
    postal_code: str
    is_primary: bool = False

class UserProfile(BaseModel):
    bio: Optional[str] = None
    avatar_url: Optional[str] = None
    preferences: dict[str, str] = Field(default_factory=dict)

class User(BaseModel):
    id: UUID = Field(default_factory=uuid4)
    email: EmailStr
    created_at: datetime = Field(default_factory=datetime.utcnow)
    profile: UserProfile = Field(default_factory=UserProfile)
    addresses: List[Address] = Field(default_factory=list)
    
    @model_validator(mode='after')
    def ensure_primary_address(self) -> 'User':
        if not self.addresses:
            return self
            
        primary_addresses = [addr for addr in self.addresses if addr.is_primary]
        if not primary_addresses:
            # Make the first address primary if none are marked
            self.addresses[0] = Address(**{**self.addresses[0].model_dump(), "is_primary": True})
        elif len(primary_addresses) > 1:
            raise ValueError("Only one address can be marked as primary")
        
        return self
""",
            "database_models": """
from sqlalchemy import Column, Integer, String, Boolean
from sqlalchemy.ext.declarative import declarative_base
from pydantic import BaseModel, Field, ConfigDict

SQLBase = declarative_base()

# SQLAlchemy database model
class UserDB(SQLBase):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True)
    email = Column(String, unique=True, nullable=False)
    hashed_password = Column(String, nullable=False)
    is_active = Column(Boolean, default=True)

# Pydantic models for API layer
class UserBase(BaseModel):
    email: str
    is_active: bool = True

class UserCreate(UserBase):
    password: str  # Clear-text only for request
    
    model_config = ConfigDict(extra="forbid")  # Reject extra fields

class UserUpdate(BaseModel):
    email: str | None = None
    is_active: bool | None = None
    
    model_config = ConfigDict(extra="forbid")

class UserInDB(UserBase):
    id: int
    hashed_password: str
    
    # Configure model to work with SQLAlchemy
    model_config = ConfigDict(from_attributes=True)

class UserResponse(UserBase):
    id: int
    
    # Configure model to work with SQLAlchemy
    model_config = ConfigDict(from_attributes=True)
""",
            "error_handling": """
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import ValidationError
from typing import Any, Dict, List

app = FastAPI()

class ErrorDetail(BaseModel):
    loc: List[str]  # Location of the error
    msg: str        # Error message
    type: str       # Error type

class ErrorResponse(BaseModel):
    detail: List[ErrorDetail]

@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors()},
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    if isinstance(exc.detail, str):
        # Convert simple string error to structured format
        detail = [{"loc": ["body"], "msg": exc.detail, "type": "request_validation"}]
    else:
        detail = exc.detail
        
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": detail},
    )
"""
        }
        
        # FastAPI integration example
        self.fastapi_integration = """
from fastapi import FastAPI, HTTPException, Path, Query, Depends
from typing import List, Optional, Annotated
# Assume schemas.py defines UserRequest (for input) and UserResponse (for output)
from .schemas import UserRequest, UserResponse, ErrorResponse
from .models import User
from .config import get_settings

app = FastAPI()
settings = get_settings()

# FastAPI automatically validates the request body against UserRequest
# and serializes the return value using UserResponse.model_dump()
@app.post(
    "/users", 
    response_model=UserResponse, 
    status_code=201,
    responses={
        400: {"model": ErrorResponse, "description": "Bad Request"},
        409: {"model": ErrorResponse, "description": "User already exists"}
    }
)
async def create_user(user_payload: UserRequest) -> UserResponse:
    # user_payload is a validated Pydantic model instance
    # ... (process the user_payload, e.g., save to database) ...
    created_user_data = {"id": 123, **user_payload.model_dump()}
    # Return data that conforms to UserResponse
    return UserResponse(**created_user_data)

# Path and query parameters with Pydantic validation
@app.get(
    "/users/{user_id}",
    response_model=UserResponse,
    responses={404: {"model": ErrorResponse}}
)
async def get_user(
    user_id: Annotated[int, Path(gt=0, description="The ID of the user to retrieve")],
    include_details: Annotated[bool, Query(default=False)] = False
) -> UserResponse:
    # Path validation happens automatically
    # ... fetch user from database ...
    return UserResponse(id=user_id, email="user@example.com", is_active=True)

# Using a dependency to inject settings
def get_db_session(settings = Depends(get_settings)):
    # Use settings.database_url to establish connection
    # ...
    try:
        db = DatabaseSession(settings.database_url)
        yield db
    finally:
        db.close()

@app.get("/users", response_model=List[UserResponse])
async def list_users(
    skip: Annotated[int, Query(ge=0, default=0)],
    limit: Annotated[int, Query(ge=1, le=100, default=10)],
    db: DatabaseSession = Depends(get_db_session)
) -> List[UserResponse]:
    # Both API parameters and dependencies leverage Pydantic validation
    # ...
    return [UserResponse(id=1, email="user@example.com", is_active=True)]
"""
    
    def get_model_by_name(self, name: str) -> Optional[PydanticModel]:
        """Find a model by name"""
        for model in self.example_models:
            if model.name == name:
                return model
        return None
    
    def get_related_models(self, model_name: str) -> List[PydanticModel]:
        """Find all models related to the specified model"""
        model = self.get_model_by_name(model_name)
        if not model:
            return []
            
        related = []
        for related_name in model.related_models:
            related_model = self.get_model_by_name(related_name)
            if related_model:
                related.append(related_model)
                
        return related
    
    def get_model_by_type(self, model_type: ModelType) -> List[PydanticModel]:
        """Find all models of a specific type"""
        return [model for model in self.example_models if model.model_type == model_type]
    
    def generate_settings_example(self, include_env_vars: bool = True) -> str:
        """Generate a settings example with environment variables"""
        settings_model = self.get_model_by_name("Settings")
        if not settings_model:
            return ""
            
        result = settings_model.code
        
        if include_env_vars:
            result += "\n\n# Example .env file:\n"
            result += "DATABASE_URL=postgresql://user:password@localhost:5432/app\n"
            result += "DEBUG=false\n"
            result += "# REDIS_URL=redis://localhost:6379/0  # Optional\n"
            
        return result
    
    def render_folder_structure(self, structure: Dict, indent: int = 0) -> str:
        """Render the recommended folder structure as a string"""
        result = []
        for key, value in structure.items():
            if isinstance(value, dict):
                result.append(" " * indent + key)
                result.append(self.render_folder_structure(value, indent + 2))
            elif isinstance(value, list):
                result.append(" " * indent + key)
                for item in value:
                    result.append(" " * (indent + 2) + item)
                    
        return "\n".join(result)
    
    def generate_project_template(self, base_dir: Path, app_name: str) -> Dict[str, Path]:
        """
        Generate a basic project structure with Pydantic models.
        Returns a dictionary of created files.
        """
        # Create the directory structure
        src_dir = base_dir / "src" / app_name
        src_dir.mkdir(parents=True, exist_ok=True)
        
        # Create the __init__.py
        init_file = src_dir / "__init__.py"
        with open(init_file, "w") as f:
            f.write(f'"""Core package for {app_name}."""\n\n')
            f.write(f'__version__ = "0.1.0"\n')
        
        # Create models.py with the User model example
        models_file = src_dir / "models.py"
        user_model = self.get_model_by_name("User")
        with open(models_file, "w") as f:
            f.write(f'"""Core domain models for {app_name}."""\n\n')
            f.write('from pydantic import BaseModel, Field, field_validator\n')
            f.write('from pydantic_core import PydanticCustomError\n\n')
            f.write(textwrap.dedent(user_model.code.strip() if user_model else ""))
        
        # Create config.py with Settings model
        config_file = src_dir / "config.py"
        settings_model = self.get_model_by_name("Settings")
        with open(config_file, "w") as f:
            f.write(f'"""Configuration management for {app_name}."""\n\n')
            f.write(textwrap.dedent(settings_model.code.strip() if settings_model else ""))
        
        # Create schemas.py with API models
        schemas_file = src_dir / "schemas.py"
        with open(schemas_file, "w") as f:
            f.write(f'"""API schema models for {app_name}."""\n\n')
            f.write('from pydantic import BaseModel, Field, EmailStr\n')
            f.write('from typing import List, Optional\n\n')
            f.write('class UserBase(BaseModel):\n')
            f.write('    """Base user attributes shared across schemas."""\n')
            f.write('    email: str\n')
            f.write('    is_active: bool = True\n\n')
            f.write('class UserCreate(UserBase):\n')
            f.write('    """Schema for creating a new user."""\n')
            f.write('    password: str\n\n')
            f.write('class UserResponse(UserBase):\n')
            f.write('    """Schema for user responses."""\n')
            f.write('    id: int\n\n')
            f.write('class ErrorDetail(BaseModel):\n')
            f.write('    """Details of a validation error."""\n')
            f.write('    loc: List[str]  # Location of the error\n')
            f.write('    msg: str        # Error message\n')
            f.write('    type: str       # Error type\n\n')
            f.write('class ErrorResponse(BaseModel):\n')
            f.write('    """Standard error response."""\n')
            f.write('    detail: List[ErrorDetail]\n')
        
        # Create .env file
        env_file = base_dir / ".env"
        with open(env_file, "w") as f:
            f.write('# Environment variables for development\n')
            f.write('DEBUG=true\n')
            f.write('DATABASE_URL=postgresql://user:password@localhost:5432/dev\n')
        
        # Create pyproject.toml with tool configs
        pyproject_file = base_dir / "pyproject.toml"
        with open(pyproject_file, "w") as f:
            f.write('[build-system]\n')
            f.write('requires = ["hatchling"]\n')
            f.write('build-backend = "hatchling.build"\n\n')
            f.write(f'[project]\n')
            f.write(f'name = "{app_name}"\n')
            f.write('version = "0.1.0"\n')
            f.write(f'description = "{app_name} project"\n')
            f.write('requires-python = ">=3.9"\n')
            f.write('dependencies = [\n')
            f.write('    "pydantic>=2.0",\n')
            f.write('    "pydantic-settings",\n')
            f.write(']\n\n')
            
            # Add mypy config
            mypy_config = next((tc for tc in self.tooling_configs if tc.tool == "mypy"), None)
            if mypy_config:
                f.write(textwrap.dedent(mypy_config.config_snippet.strip()) + '\n\n')
            
            # Add ruff config
            ruff_config = next((tc for tc in self.tooling_configs if tc.tool == "ruff"), None)
            if ruff_config:
                f.write(textwrap.dedent(ruff_config.config_snippet.strip()) + '\n')
        
        return {
            "init": init_file,
            "models": models_file,
            "config": config_file,
            "schemas": schemas_file,
            "env": env_file,
            "pyproject": pyproject_file
        }
    
    def __str__(self) -> str:
        """String representation of data validation standards"""
        return f"{self.name}: Using Pydantic {self.min_version}+ for data validation and configuration"


# Example usage
if __name__ == "__main__":
    validation = DataValidationAndConfiguration()
    
    print(f"ðŸ“Š {validation}")
    
    print("\nðŸ”‘ Core Principles:")
    for i, principle in enumerate(validation.core_principles, 1):
        print(f"{i}. {principle.name}: {principle.description}")
    
    print("\nðŸ“ Recommended Project Layout:")
    print("```")
    print(validation.render_folder_structure(validation.recommended_layout))
    print("```")
    
    print("\nðŸ“‹ Example Models:")
    for model in validation.example_models:
        print(f"- {model.name} ({model.model_type.value}): {model.description}")
    
    print("\nâš™ï¸ Tooling Configuration:")
    for tool_config in validation.tooling_configs:
        print(f"- {tool_config.tool}: {tool_config.purpose}")
    
    print("\nðŸ” Example Usage:")
    user_model = validation.get_model_by_name("User")
    if user_model:
        print(f"User Model Example:\n```python\n{textwrap.dedent(user_model.code)}\n```")
    
    print("\nðŸ§© Advanced Patterns:")
    print("1. Nested Models and Relationships")
    print("2. Database Model Integration")
    print("3. Error Handling")
    
    print("\nðŸ’¡ Try running the `.generate_project_template()` method to create a starter project structure.")./tasks.py
from dataclasses import dataclass, field
from typing import List, Dict, Set, Optional, Any, Tuple, Union
from enum import Enum
import os
import json
import textwrap
import jinja2


class WorkloadType(Enum):
    """Types of workloads that determine concurrency approach"""
    IO_BOUND = "I/O-Bound Operations (Network, Disk)"
    CPU_BOUND = "CPU-Bound Operations (Intensive Calculations)"
    BLOCKING_WITH_ASYNCIO = "Integrating Blocking Libraries with asyncio"


@dataclass
class ConcurrencyModel:
    """Represents a concurrency model for Python"""
    name: str
    workload_type: WorkloadType
    rationale: str
    key_libraries: List[str]
    example_code: str = ""


@dataclass
class TaskQueueConfig:
    """Configuration for Celery task queues"""
    broker: str
    backend: Optional[str] = None
    acks_late: bool = True
    autoretry_for: Tuple[str, ...] = ("Exception",)
    retry_backoff: bool = True
    max_retries: int = 5
    soft_time_limit: int = 60
    time_limit: int = 70
    serializer: str = "json"
    
    def get_config_dict(self) -> Dict[str, Any]:
        """Return configuration as a dictionary for Celery app.conf.update()"""
        return {
            "broker_url": self.broker,
            "result_backend": self.backend if self.backend else None,
            "task_acks_late": self.acks_late,
            "task_serializer": self.serializer,
            "accept_content": [self.serializer],
            "result_serializer": self.serializer,
            "timezone": "UTC",
            "enable_utc": True,
        }


@dataclass
class MessagingSystem:
    """Represents a messaging or streaming system"""
    name: str
    url: str
    key_use_cases: List[str]
    notes: str
    python_libraries: List[str]
    is_cloud_native: bool = False


@dataclass
class TestingStrategy:
    """Strategy for testing asynchronous components"""
    component_type: str
    testing_tools: List[str]
    description: str
    example_code: Optional[str] = None


@dataclass
class AsyncComponentDoc:
    """Documentation requirements for async components"""
    component_name: str
    purpose: str
    schema: str
    idempotency_strategy: str
    producers: List[str]
    consumers: List[str]
    error_handling: str
    monitoring: str
    performance_expectations: Optional[str] = None


class BackgroundTasksAndConcurrency:
    """
    Background Tasks, Messaging & Concurrency
    
    A class representing best practices for handling operations outside 
    the main request-response cycle, including concurrency models,
    background tasks, and messaging systems.
    """
    
    def __init__(self):
        self.name = "Background Tasks, Messaging & Concurrency"
        
        # Initialize the foundational concurrency models
        self.concurrency_models = [
            ConcurrencyModel(
                name="asyncio",
                workload_type=WorkloadType.IO_BOUND,
                rationale="Efficiently handles many concurrent I/O operations with minimal thread overhead.",
                key_libraries=["FastAPI", "httpx", "asyncpg", "aioredis"],
                example_code="""
async def fetch_user_data(user_id: str):
    async with httpx.AsyncClient() as client:
        response = await client.get(f"https://api.example.com/users/{user_id}")
        response.raise_for_status()
        return response.json()
"""
            ),
            ConcurrencyModel(
                name="multiprocessing",
                workload_type=WorkloadType.CPU_BOUND,
                rationale="Bypasses the Global Interpreter Lock (GIL) for true parallelism across CPU cores.",
                key_libraries=["multiprocessing", "Celery with prefork pool", "Kubernetes Jobs"],
                example_code="""
from multiprocessing import Pool

def cpu_intensive_task(data):
    # Complex calculation
    result = perform_calculation(data)
    return result

def process_in_parallel(data_list):
    with Pool(processes=os.cpu_count()) as pool:
        results = pool.map(cpu_intensive_task, data_list)
    return results
"""
            ),
            ConcurrencyModel(
                name="ThreadPoolExecutor",
                workload_type=WorkloadType.BLOCKING_WITH_ASYNCIO,
                rationale="Prevents blocking the asyncio event loop when using synchronous, blocking libraries.",
                key_libraries=["anyio.to_thread.run_sync", "asyncio.to_thread"],
                example_code="""
import asyncio
from PIL import Image  # A blocking library

async def process_image(image_path: str):
    # Use asyncio.to_thread to run the blocking operation in a thread
    image = await asyncio.to_thread(Image.open, image_path)
    # More processing...
    return image
"""
            )
        ]
        
        # Celery best practices
        self.celery_best_practices = [
            "Tasks must be designed to be idempotent.",
            "Implement robust retry mechanisms with exponential backoff.",
            "Enable late acknowledgement (acks_late=True) so tasks are re-queued if a worker crashes.",
            "Guard against runaway tasks with soft_time_limit and time_limit.",
            "Emit task events for monitoring and observability.",
            "Use json serializer for broad compatibility."
        ]
        
        # Celery broker recommendations
        self.celery_brokers = {
            "development": ["Redis 7+"],
            "production": ["RabbitMQ 3.13+", "Google Cloud Pub/Sub", "Amazon SQS"]
        }
        
        # Task queue configuration examples
        self.task_queue_configs = {
            "development": TaskQueueConfig(
                broker="redis://localhost:6379/0",
                backend="redis://localhost:6379/1"
            ),
            "production": TaskQueueConfig(
                broker="amqp://user:password@rabbitmq:5672//",
                backend="redis://redis:6379/0",
                max_retries=10,
                soft_time_limit=120,
                time_limit=150
            ),
            "cloud": TaskQueueConfig(
                broker="pubsub://",
                backend=None,  # Results stored in database or disabled
                max_retries=15,
                soft_time_limit=300,
                time_limit=360
            )
        }
        
        # Messaging systems
        self.messaging_systems = [
            MessagingSystem(
                name="Google Cloud Pub/Sub",
                url="https://cloud.google.com/pubsub",
                key_use_cases=[
                    "Cloud-native, highly scalable (10k+ msg/s)",
                    "Global fan-out",
                    "At-least-once delivery"
                ],
                notes="Excellent for serverless functions, HTTP push subscriptions for near-real-time callbacks. Managed service reduces operational overhead.",
                python_libraries=["google-cloud-pubsub"],
                is_cloud_native=True
            ),
            MessagingSystem(
                name="Apache Kafka",
                url="https://kafka.apache.org/",
                key_use_cases=[
                    "High-volume ordered event streams",
                    "Log-based auditing",
                    "Stream processing",
                    "Event sourcing"
                ],
                notes="Powerful but complex to operate self-hosted. Prefer managed services like Confluent Cloud, Amazon MSK, or Aiven for Apache Kafka.",
                python_libraries=["confluent-kafka", "aiokafka"],
                is_cloud_native=False
            ),
            MessagingSystem(
                name="NATS.io",
                url="https://nats.io/",
                key_use_cases=[
                    "Ultra-lightweight",
                    "Very low latency (<1 ms)",
                    "Request-reply patterns",
                    "Simple pub/sub"
                ],
                notes="Good for internal microservice communication within Kubernetes. Supports various messaging patterns including JetStream for persistence.",
                python_libraries=["nats-py"],
                is_cloud_native=False
            ),
            MessagingSystem(
                name="RabbitMQ",
                url="https://www.rabbitmq.com/",
                key_use_cases=[
                    "Flexible routing",
                    "Multiple protocol support (AMQP, MQTT, STOMP)",
                    "Mature ecosystem"
                ],
                notes="Can be used as a Celery broker or a general-purpose message bus. Requires careful operational management if self-hosted.",
                python_libraries=["pika", "aio-pika"],
                is_cloud_native=False
            )
        ]
        
        # Testing strategies
        self.testing_strategies = [
            TestingStrategy(
                component_type="Celery",
                testing_tools=["pytest-celery"],
                description="Manages an embedded Celery worker during integration tests",
                example_code="""
# Example pytest fixture for Celery testing
@pytest.fixture
def celery_app():
    app = Celery("test_app")
    app.conf.update(
        broker_url="memory://",
        result_backend="cache+memory://",
        task_always_eager=True,  # Tasks execute synchronously for testing
        task_eager_propagates=True  # Exceptions are propagated
    )
    return app

def test_celery_task(celery_app):
    # Register the task with the test app
    @celery_app.task
    def add(x, y):
        return x + y
    
    # Execute the task
    result = add.delay(4, 4)
    assert result.get() == 8
"""
            ),
            TestingStrategy(
                component_type="Google Pub/Sub",
                testing_tools=["google-cloud-pubsub-emulator"],
                description="Uses the official Google Pub/Sub emulator for local testing",
                example_code="""
# Start the emulator before tests:
# $ gcloud beta emulators pubsub start --project=test-project

# In your test code:
import os
os.environ["PUBSUB_EMULATOR_HOST"] = "localhost:8085"

from google.cloud import pubsub_v1

def test_pubsub_subscription():
    # Create client with emulator
    publisher = pubsub_v1.PublisherClient()
    subscriber = pubsub_v1.SubscriberClient()
    
    # Create topic and subscription for testing
    topic_path = publisher.topic_path("test-project", "test-topic")
    sub_path = subscriber.subscription_path("test-project", "test-sub")
    
    # Test publishing and receiving
    # ...
"""
            ),
            TestingStrategy(
                component_type="Kafka",
                testing_tools=["testcontainers-python"],
                description="Spins up a Kafka container for testing",
                example_code="""
from testcontainers.kafka import KafkaContainer
import pytest

@pytest.fixture(scope="session")
def kafka_container():
    with KafkaContainer() as kafka:
        yield kafka

def test_kafka_producer(kafka_container):
    from confluent_kafka import Producer
    
    # Configure producer with container address
    bootstrap_servers = kafka_container.get_bootstrap_server()
    producer = Producer({"bootstrap.servers": bootstrap_servers})
    
    # Test producing messages
    # ...
"""
            )
        ]
        
        # Documentation template
        self.doc_template = {
            "component_name": "",
            "purpose": "",
            "schema": "",
            "idempotency_strategy": "",
            "producers": [],
            "consumers": [],
            "error_handling": "",
            "monitoring": "",
            "performance_expectations": ""
        }
        
        # General guidelines
        self.general_guidelines = [
            "Avoid blocking in async def: Never call blocking I/O operations directly within an async function.",
            "Thread Pool Sizing: For ThreadPoolExecutor, keep the pool size to CPU_CORES * 2 or CPU_CORES + 4.",
            "FastAPI Routes: For quick work (<20ms), keep it synchronous. For I/O-bound work up to ~200ms, use async def.",
            "For operations taking >200ms, use Celery or other background task systems."
        ]
        
        # Messaging practices
        self.messaging_practices = [
            "Schematized Payloads: Use well-defined schemas (Avro, Protocol Buffers) or JSON with Pydantic models.",
            "Traceability: Include distributed tracing headers in messages for correlation.",
            "Consumer Logic Location: Organize consumer code in /app/subscribers/ or /app/consumers/ directories.",
            "Dead-Letter Queues: Configure DLQs to handle messages that fail after multiple retries."
        ]
    
    def get_concurrency_model(self, workload_type: WorkloadType) -> ConcurrencyModel:
        """Return the recommended concurrency model for a specific workload type"""
        for model in self.concurrency_models:
            if model.workload_type == workload_type:
                return model
        raise ValueError(f"No concurrency model found for workload type: {workload_type}")
    
    def get_celery_task_decorator(self, task_type: str = "default") -> str:
        """
        Generate a Celery task decorator with recommended settings
        based on the task type.
        """
        if task_type == "cpu_bound":
            return "@app.task(acks_late=True, autoretry_for=(Exception,), retry_backoff=True, max_retries=3, soft_time_limit=120, time_limit=150)"
        elif task_type == "io_bound":
            return "@app.task(acks_late=True, autoretry_for=(IOError,), retry_backoff=True, retry_jitter=True, max_retries=5)"
        else:  # default
            return "@app.task(acks_late=True, autoretry_for=(Exception,), retry_backoff=True, max_retries=3, soft_time_limit=60, time_limit=70)"
    
    def get_celery_example(self) -> str:
        """Return the Celery minimal example code"""
        return """
# project/tasks.py
from celery import Celery
import time

# Configuration should ideally come from a central config module or environment variables
app = Celery(
    "my_app_tasks",
    broker="redis://localhost:6379/0", # Example: Connect to local Redis
    backend="redis://localhost:6379/1"
)

# Optional: Configure Celery app further (e.g., task routes, serializers)
app.conf.update(
    task_serializer='json',
    accept_content=['json'],  # Ensure Celery accepts JSON
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
)

@app.task(acks_late=True, autoretry_for=(Exception,), retry_backoff=True, max_retries=3, soft_time_limit=60, time_limit=70)
def add(x: int, y: int) -> int:
    # Simulate some work
    time.sleep(2)
    result = x + y
    # logger.info(f"Task add({x}, {y}) completed with result: {result}") # Use proper logging
    return result

@app.task(bind=True, acks_late=True, autoretry_for=(IOError,), retry_backoff=True, retry_jitter=True, max_retries=5)
def process_file(self, filepath: str):
    try:
        # Simulate file processing
        # logger.info(f"Processing file: {filepath}")
        if "fail" in filepath:
            raise IOError("Simulated file access error")
        time.sleep(5)
        # logger.info(f"File {filepath} processed successfully.")
        return f"Successfully processed {filepath}"
    except Exception as exc:
        # logger.error(f"Task process_file failed for {filepath}. Retrying ({self.request.retries}/{self.max_retries})...", exc_info=True)
        raise self.retry(exc=exc)
"""
    
    def get_docker_compose_celery(self) -> str:
        """Return a Docker Compose example for Celery"""
        return """
# compose.celery.yml
version: '3.8'

services:
  worker:
    build: .
    command: celery -A project.tasks worker -l INFO
    volumes:
      - .:/app
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://user:password@db:5432/app
    depends_on:
      - redis
      - db
  
  beat:
    build: .
    command: celery -A project.tasks beat -l INFO
    volumes:
      - .:/app
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
      - worker
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
  
  db:
    image: postgres:14-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=app
    volumes:
      - postgres-data:/var/lib/postgresql/data

volumes:
  redis-data:
  postgres-data:
"""
    
    def generate_docker_compose(self, template_name: str, context: Dict[str, Any]) -> str:
        """
        Generate a Docker Compose file from a Jinja2 template with the provided context.
        
        Args:
            template_name: The name of the template to use
            context: Dictionary of values to render in the template
            
        Returns:
            The rendered Docker Compose YAML as a string
        """
        templates = {
            "celery": """
# {{ filename }}
version: '{{ version }}'

services:
  worker:
    build: {% if build_context %}{{ build_context }}{% else %}.{% endif %}
    {% if worker_image %}image: {{ worker_image }}
    {% endif %}command: celery -A {{ celery_app }} worker -l {{ log_level }}
    volumes:
      - .:/app
    environment:
      - REDIS_URL={{ redis_url }}
      {% if database_url %}- DATABASE_URL={{ database_url }}{% endif %}
    depends_on:
      - redis
      {% if use_database %}- db{% endif %}
  
  {% if include_beat %}
  beat:
    {% if worker_image %}image: {{ worker_image }}
    {% else %}build: {% if build_context %}{{ build_context }}{% else %}.{% endif %}{% endif %}
    command: celery -A {{ celery_app }} beat -l {{ log_level }}
    volumes:
      - .:/app
    environment:
      - REDIS_URL={{ redis_url }}
    depends_on:
      - redis
      - worker
  {% endif %}
  
  redis:
    image: {{ redis_image }}
    ports:
      - "{{ redis_port }}:6379"
    volumes:
      - redis-data:/data
  
  {% if use_database %}
  db:
    image: {{ db_image }}
    environment:
      - POSTGRES_USER={{ db_user }}
      - POSTGRES_PASSWORD={{ db_password }}
      - POSTGRES_DB={{ db_name }}
    volumes:
      - postgres-data:/var/lib/postgresql/data
  {% endif %}

volumes:
  redis-data:
  {% if use_database %}postgres-data:{% endif %}
""",
            "kafka": """
# {{ filename }}
version: '{{ version }}'

services:
  zookeeper:
    image: {{ zookeeper_image }}
    ports:
      - "{{ zookeeper_port }}:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log

  kafka:
    image: {{ kafka_image }}
    ports:
      - "{{ kafka_port }}:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    volumes:
      - kafka-data:/var/lib/kafka/data
    depends_on:
      - zookeeper
      
  {% if include_schema_registry %}
  schema-registry:
    image: {{ schema_registry_image }}
    ports:
      - "{{ schema_registry_port }}:8081"
    environment:
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - kafka
  {% endif %}
  
  {% if include_kafka_ui %}
  kafka-ui:
    image: {{ kafka_ui_image }}
    ports:
      - "{{ kafka_ui_port }}:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME={{ cluster_name }}
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      {% if include_schema_registry %}- KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schema-registry:8081{% endif %}
    depends_on:
      - kafka
      {% if include_schema_registry %}- schema-registry{% endif %}
  {% endif %}

volumes:
  zookeeper-data:
  zookeeper-log:
  kafka-data:
""",
            "rabbitmq": """
# {{ filename }}
version: '{{ version }}'

services:
  rabbitmq:
    image: {{ rabbitmq_image }}
    ports:
      - "{{ rabbitmq_port }}:5672"
      {% if management_enabled %}- "{{ management_port }}:15672"{% endif %}
    environment:
      - RABBITMQ_DEFAULT_USER={{ rabbitmq_user }}
      - RABBITMQ_DEFAULT_PASS={{ rabbitmq_password }}
      {% if management_enabled %}- RABBITMQ_MANAGEMENT_ENABLE=true{% endif %}
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      
volumes:
  rabbitmq-data:
"""
        }
        
        # Set default values if not provided in the context
        defaults = {
            "version": "3.8",
            "filename": f"docker-compose-{template_name}.yml",
            "log_level": "INFO",
        }
        
        # Add template-specific defaults
        if template_name == "celery":
            defaults.update({
                "redis_image": "redis:7-alpine",
                "redis_port": "6379", 
                "redis_url": "redis://redis:6379/0",
                "celery_app": "project.tasks",
                "use_database": True,
                "db_image": "postgres:14-alpine",
                "db_user": "user",
                "db_password": "password",
                "db_name": "app",
                "include_beat": True,
            })
        elif template_name == "kafka":
            defaults.update({
                "zookeeper_image": "confluentinc/cp-zookeeper:7.3.0",
                "kafka_image": "confluentinc/cp-kafka:7.3.0",
                "zookeeper_port": "2181",
                "kafka_port": "9092",
                "include_schema_registry": False,
                "schema_registry_image": "confluentinc/cp-schema-registry:7.3.0",
                "schema_registry_port": "8081",
                "include_kafka_ui": False,
                "kafka_ui_image": "provectuslabs/kafka-ui:latest",
                "kafka_ui_port": "8080",
                "cluster_name": "local-kafka",
            })
        elif template_name == "rabbitmq":
            defaults.update({
                "rabbitmq_image": "rabbitmq:3.13-management",
                "rabbitmq_port": "5672",
                "management_enabled": True,
                "management_port": "15672",
                "rabbitmq_user": "guest",
                "rabbitmq_password": "guest",
            })
        
        # Merge the provided context with defaults
        for key, value in defaults.items():
            if key not in context:
                context[key] = value
                
        if template_name not in templates:
            raise ValueError(f"Template '{template_name}' not found. Available templates: {', '.join(templates.keys())}")
        
        # Render the template
        template = jinja2.Template(templates[template_name])
        return template.render(**context)
    
    def create_async_component_doc(self, **kwargs) -> AsyncComponentDoc:
        """
        Create documentation for an asynchronous component following
        the required format.
        """
        # Validate that all required fields are present
        required_fields = ["component_name", "purpose", "schema", "idempotency_strategy", 
                           "producers", "consumers", "error_handling", "monitoring"]
        
        for field in required_fields:
            if field not in kwargs:
                raise ValueError(f"Missing required field: {field}")
        
        return AsyncComponentDoc(**kwargs)
    
    def get_async_component_doc_template(self) -> str:
        """Return a Markdown template for documenting async components"""
        return """
# Asynchronous Component Documentation

## {component_name}

**Purpose:** {purpose}

**Message/Task Schema:**
```json
{schema}
```

**Idempotency Strategy:**
{idempotency_strategy}

**Producers:**
{producers}

**Consumers:**
{consumers}

**Error Handling & Retry Policy:**
{error_handling}

**Monitoring & Alerting:**
{monitoring}

{performance_section}
"""
    
    def render_async_component_doc(self, doc: AsyncComponentDoc) -> str:
        """Render documentation for an async component as Markdown"""
        # Format producers and consumers as bullet points
        producers_md = "\n".join([f"- {producer}" for producer in doc.producers])
        consumers_md = "\n".join([f"- {consumer}" for consumer in doc.consumers])
        
        # Add performance section if available
        performance_section = ""
        if doc.performance_expectations:
            performance_section = f"**Performance Expectations:**\n{doc.performance_expectations}"
        
        template = self.get_async_component_doc_template()
        return template.format(
            component_name=doc.component_name,
            purpose=doc.purpose,
            schema=doc.schema,
            idempotency_strategy=doc.idempotency_strategy,
            producers=producers_md,
            consumers=consumers_md,
            error_handling=doc.error_handling,
            monitoring=doc.monitoring,
            performance_section=performance_section
        )
    
    def get_recommended_messaging_system(self, use_case: str) -> List[MessagingSystem]:
        """Find messaging systems suitable for a specific use case"""
        recommendations = []
        for system in self.messaging_systems:
            if any(use_case.lower() in case.lower() for case in system.key_use_cases):
                recommendations.append(system)
        
        return recommendations if recommendations else self.messaging_systems
    
    def __str__(self) -> str:
        """String representation of background tasks and concurrency guidelines"""
        return f"{self.name}: Strategies for managing concurrency, background tasks, and messaging systems"


# Example usage
if __name__ == "__main__":
    bg_tasks = BackgroundTasksAndConcurrency()
    
    print(f"ðŸ”„ {bg_tasks}")
    
    print("\nâš¡ Concurrency Models:")
    for model in bg_tasks.concurrency_models:
        print(f"- {model.name}: For {model.workload_type.value}")
        print(f"  Rationale: {model.rationale}")
        print(f"  Key Libraries: {', '.join(model.key_libraries)}")
    
    print("\nðŸ§µ General Concurrency Guidelines:")
    for i, guideline in enumerate(bg_tasks.general_guidelines, 1):
        print(f"{i}. {guideline}")
    
    print("\nðŸŽ¯ Celery Best Practices:")
    for i, practice in enumerate(bg_tasks.celery_best_practices, 1):
        print(f"{i}. {practice}")
    
    print("\nðŸ“¨ Messaging Systems:")
    for system in bg_tasks.messaging_systems:
        print(f"- {system.name}")
        print(f"  URL: {system.url}")
        print(f"  Use Cases: {', '.join(system.key_use_cases)}")
    
    print("\nðŸ§ª Testing Strategies:")
    for strategy in bg_tasks.testing_strategies:
        print(f"- Testing {strategy.component_type} with {', '.join(strategy.testing_tools)}")
        print(f"  {strategy.description}")
    
    print("\nðŸ“ Documentation Requirements:")
    doc_example = bg_tasks.create_async_component_doc(
        component_name="order_processing_queue",
        purpose="Process new customer orders asynchronously to ensure fast API responses",
        schema='{"order_id": "string", "items": [{"product_id": "string", "quantity": "integer"}], "customer_id": "string", "timestamp": "string"}',
        idempotency_strategy="Orders are processed exactly once using the order_id as a unique key in the database",
        producers=["API Order Service", "Batch Import Service"],
        consumers=["Order Processing Worker"],
        error_handling="Automatic retry with exponential backoff, max 5 retries. Failed orders moved to dead-letter queue and flagged for manual intervention.",
        monitoring="Queue depth, processing time, and error rate are monitored via Prometheus and Grafana dashboards",
        performance_expectations="Expected to handle up to 1000 orders per minute with processing time < 2 seconds per order"
    )
    
    print(bg_tasks.render_async_component_doc(doc_example))
./git_branching.py
#!/usr/bin/env python3
"""
Git Branching Strategy Implementation

This module provides utilities and best practices for implementing a consistent Git branching strategy.
It enforces a structured workflow that improves collaboration and maintains a clean project history.

Key benefits of a consistent branching strategy:
- Clear separation between production, development, and feature work
- Easier collaboration among team members
- Cleaner project history with meaningful commits
- Safer deployment process with reduced risk of issues in production
"""

from dataclasses import dataclass
import subprocess
import sys
from typing import Optional, List
from datetime import datetime


@dataclass
class BranchingStrategy:
    """
    Represents a Git branching strategy based on the widely-adopted GitFlow approach.
    
    This strategy defines how branches should be named and managed throughout the
    development lifecycle. Following this approach provides several benefits:
    
    - Isolates new development from production code
    - Enables parallel development by multiple team members
    - Organizes branches by purpose (features, bugfixes, hotfixes)
    - Maintains a clean and meaningful commit history
    """
    main_branch: str
    development_branch: str
    feature_prefix: str
    bugfix_prefix: str
    hotfix_prefix: str
    
    @classmethod
    def default_strategy(cls) -> "BranchingStrategy":
        """
        Returns the recommended default branching strategy.
        
        Main branch (main): 
        - Contains production-ready code
        - Should always be deployable
        - Never commit directly to this branch
        
        Development branch (dev):
        - Contains code in active development for the next release
        - Features are merged here first for integration testing
        
        Feature branches (feature/*):
        - Created from the development branch
        - Used for developing new features
        - Merged back into development when complete
        
        Bugfix branches (bugfix/*):
        - Created from the main branch
        - Used for fixing issues in production
        - Merged to both main and development branches
        
        Hotfix branches (hotfix/*):
        - Used for critical production fixes
        - Created from main, merged to both main and development
        """
        return cls(
            main_branch="main",
            development_branch="dev",
            feature_prefix="feature/",
            bugfix_prefix="bugfix/",
            hotfix_prefix="hotfix/"
        )


class GitBranching:
    """
    Utility class for Git branch management following best practices.
    
    This class provides methods to create and manage branches according to a 
    consistent branching strategy. It enforces workflows that help maintain 
    a clean repository history and facilitate collaborative development.
    
    Best practices enforced:
    1. Feature branches always derive from development branch
    2. Bugfix branches always derive from main branch
    3. Hotfix branches always derive from main branch
    4. Non-fast-forward merges to preserve branch history
    5. Validation of branch existence before operations
    """
    
    def __init__(self, strategy: Optional[BranchingStrategy] = None):
        """
        Initialize with a branching strategy, or use the default.
        
        Args:
            strategy: Custom branching strategy configuration. If None, uses the default.
        """
        self.strategy = strategy or BranchingStrategy.default_strategy()
        print(f"ðŸ”„ Initialized Git branching with strategy:")
        print(f"  â€¢ Main branch: {self.strategy.main_branch}")
        print(f"  â€¢ Development branch: {self.strategy.development_branch}")
        print(f"  â€¢ Feature branches: {self.strategy.feature_prefix}*")
        print(f"  â€¢ Bugfix branches: {self.strategy.bugfix_prefix}*")
        print(f"  â€¢ Hotfix branches: {self.strategy.hotfix_prefix}*")
    
    def branch_exists(self, branch_name: str) -> bool:
        """
        Check if a branch exists.
        
        Args:
            branch_name: The name of the branch to check
            
        Returns:
            True if the branch exists, False otherwise
        """
        result = subprocess.run(
            ["git", "rev-parse", "--verify", branch_name],
            capture_output=True,
            text=True
        )
        return result.returncode == 0
    
    def branch_has_upstream(self, branch_name: str) -> bool:
        """
        Check if a branch has an upstream tracking branch.
        
        Args:
            branch_name: The name of the branch to check
            
        Returns:
            True if the branch has an upstream, False otherwise
        """
        result = subprocess.run(
            ["git", "rev-parse", "--abbrev-ref", f"{branch_name}@{{upstream}}"],
            capture_output=True,
            text=True
        )
        return result.returncode == 0
    
    def create_feature_branch(self, feature_name: str) -> str:
        """
        Create a new feature branch from the development branch.
        
        Args:
            feature_name: The name of the feature (without prefix)
            
        Returns:
            The full command that was executed
        """
        branch_name = f"{self.strategy.feature_prefix}{feature_name}"
        
        # Check if branch already exists
        if self.branch_exists(branch_name):
            print(f"  â„¹ï¸ Branch '{branch_name}' already exists. Switching to it instead of creating.")
            command = f"git checkout {branch_name}"
            self._execute_git_command(command)
            return command
        
        # Check if we should pull (only if branch has upstream tracking)
        pull_cmd = ""
        if self.branch_exists(self.strategy.development_branch):
            if self.branch_has_upstream(self.strategy.development_branch):
                pull_cmd = " && git pull"
            else:
                print(f"  â„¹ï¸ Development branch '{self.strategy.development_branch}' has no upstream. Skipping pull.")
        
        command = f"git checkout {self.strategy.development_branch}{pull_cmd} && git checkout -b {branch_name}"
        self._execute_git_command(command)
        return command
    
    def create_bugfix_branch(self, bug_name: str) -> str:
        """
        Create a new bugfix branch from the main branch.
        
        Args:
            bug_name: The name of the bugfix (without prefix)
            
        Returns:
            The full command that was executed
        """
        branch_name = f"{self.strategy.bugfix_prefix}{bug_name}"
        
        # Check if branch already exists
        if self.branch_exists(branch_name):
            print(f"  â„¹ï¸ Branch '{branch_name}' already exists. Switching to it instead of creating.")
            command = f"git checkout {branch_name}"
            self._execute_git_command(command)
            return command
        
        # Check if we should pull (only if branch has upstream tracking)
        pull_cmd = ""
        if self.branch_exists(self.strategy.main_branch):
            if self.branch_has_upstream(self.strategy.main_branch):
                pull_cmd = " && git pull"
            else:
                print(f"  â„¹ï¸ Main branch '{self.strategy.main_branch}' has no upstream. Skipping pull.")
        
        command = f"git checkout {self.strategy.main_branch}{pull_cmd} && git checkout -b {branch_name}"
        self._execute_git_command(command)
        return command
    
    def create_hotfix_branch(self, hotfix_name: str) -> str:
        """
        Create a new hotfix branch from the main branch.
        
        Args:
            hotfix_name: The name of the hotfix (without prefix)
            
        Returns:
            The full command that was executed
        """
        branch_name = f"{self.strategy.hotfix_prefix}{hotfix_name}"
        
        # Check if branch already exists
        if self.branch_exists(branch_name):
            print(f"  â„¹ï¸ Branch '{branch_name}' already exists. Switching to it instead of creating.")
            command = f"git checkout {branch_name}"
            self._execute_git_command(command)
            return command
        
        # Check if we should pull (only if branch has upstream tracking)
        pull_cmd = ""
        if self.branch_exists(self.strategy.main_branch):
            if self.branch_has_upstream(self.strategy.main_branch):
                pull_cmd = " && git pull"
            else:
                print(f"  â„¹ï¸ Main branch '{self.strategy.main_branch}' has no upstream. Skipping pull.")
        
        command = f"git checkout {self.strategy.main_branch}{pull_cmd} && git checkout -b {branch_name}"
        self._execute_git_command(command)
        return command
    
    def merge_feature_to_dev(self, feature_name: str) -> None:
        """
        Merge a feature branch back to the development branch.
        
        Args:
            feature_name: The name of the feature (without prefix)
        """
        branch_name = f"{self.strategy.feature_prefix}{feature_name}"
        
        # Check if we should pull (only if branch has upstream tracking)
        pull_cmd = ""
        if self.branch_exists(self.strategy.development_branch):
            if self.branch_has_upstream(self.strategy.development_branch):
                pull_cmd = " && git pull"
            else:
                print(f"  â„¹ï¸ Development branch '{self.strategy.development_branch}' has no upstream. Skipping pull.")
        
        self._execute_git_command(f"git checkout {self.strategy.development_branch}{pull_cmd}")
        self._execute_git_command(f"git merge --no-ff {branch_name}")
    
    def list_branches(self, prefix: Optional[str] = None) -> List[str]:
        """
        List all branches matching the given prefix.
        
        Best practice:
        - Regularly review branches to identify stale or abandoned branches
        - Clean up merged branches to keep repository tidy
        - Use branch prefixes to organize and categorize work
        
        Args:
            prefix: Branch prefix to filter by (e.g., 'feature/', 'bugfix/')
            
        Returns:
            List of branch names matching the prefix
        """
        print(f"\nðŸ“‹ Listing{'':s} branches{f' with prefix {prefix}' if prefix else ''}")
        
        result = subprocess.run(
            ["git", "branch", "--list"], 
            capture_output=True, 
            text=True,
            check=True
        )
        
        branches = [
            branch.strip().lstrip("* ") 
            for branch in result.stdout.splitlines() 
            if branch.strip()
        ]
        
        if prefix:
            branches = [branch for branch in branches if branch.startswith(prefix)]
            
        if branches:
            print(f"  âœ… Found {len(branches)} matching branches:")
            current_branch = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                capture_output=True,
                text=True,
                check=True
            ).stdout.strip()
            
            for branch in branches:
                is_current = branch == current_branch
                print(f"  {'*' if is_current else ' '} {branch}")
        else:
            print(f"  â„¹ï¸ No{f' {prefix}' if prefix else ''} branches found")
            
        return branches
    
    def _execute_git_command(self, command: str) -> subprocess.CompletedProcess:
        """
        Execute a git command.
        
        Best practice:
        - Capture command output for debugging
        - Handle errors gracefully with informative messages
        - Use shell=True for complex commands with &&
        
        Args:
            command: Git command to execute
            
        Returns:
            Completed process object
        """
        try:
            return subprocess.run(command, shell=True, check=True)
        except subprocess.CalledProcessError as e:
            print(f"  âŒ Git command failed: {e}")
            print(f"  â„¹ï¸ Command was: {command}")
            raise


if __name__ == "__main__":
    # Example usage with narrative output
    print("=" * 80)
    print("ðŸŒ¿ GIT BRANCHING STRATEGY DEMONSTRATION")
    print("=" * 80)
    print("\nThis script showcases recommended Git branching strategies and workflows")
    print("that help maintain a clean repository and facilitate collaborative development.")
    
    git = GitBranching()
    
    print("\nðŸ“š BRANCHING STRATEGY OVERVIEW:")
    print(f"  â€¢ Main branch ({git.strategy.main_branch}): Production-ready code")
    print(f"  â€¢ Development branch ({git.strategy.development_branch}): Code for next release")
    print(f"  â€¢ Feature branches ({git.strategy.feature_prefix}*): New functionality")
    print(f"  â€¢ Bugfix branches ({git.strategy.bugfix_prefix}*): Production issue fixes")
    print(f"  â€¢ Hotfix branches ({git.strategy.hotfix_prefix}*): Critical production fixes")
    
    print("\nðŸ”„ TYPICAL WORKFLOWS:")
    
    print("\n1. FEATURE DEVELOPMENT")
    print("   â†“ Start from development branch")
    print(f"   â†“ Create feature branch: {git.strategy.feature_prefix}new-feature")
    print("   â†“ Make changes and commit")
    print(f"   â†“ Merge back to {git.strategy.development_branch} with --no-ff")
    
    print("\n2. BUGFIX WORKFLOW")
    print("   â†“ Start from main branch")
    print(f"   â†“ Create bugfix branch: {git.strategy.bugfix_prefix}fix-issue")
    print("   â†“ Fix bug and commit")
    print(f"   â†“ Merge to {git.strategy.main_branch}")
    print(f"   â†“ Merge to {git.strategy.development_branch}")
    
    print("\n3. HOTFIX WORKFLOW")
    print("   â†“ Start from main branch")
    print(f"   â†“ Create hotfix branch: {git.strategy.hotfix_prefix}critical-fix")
    print("   â†“ Fix critical issue and commit")
    print(f"   â†“ Merge to {git.strategy.main_branch} with version bump")
    print("   â†“ Deploy to production")
    print(f"   â†“ Merge to {git.strategy.development_branch}")
    
    # Demonstrate creating a feature branch
    print("\nðŸ” DEMONSTRATION: Creating a feature branch")
    print("-" * 50)
    command = git.create_feature_branch("user-authentication")
    
    # List feature branches
    print("\nðŸ” DEMONSTRATION: Listing feature branches")
    print("-" * 50)
    git.list_branches(git.strategy.feature_prefix)
    
    print("\n" + "=" * 80)
    print("For more information on Git branching strategies, visit:")
    print("https://nvie.com/posts/a-successful-git-branching-model/")
    print("=" * 80)./fast_api_best_practice.py
#!/usr/bin/env python3
"""
FastAPI Best Practices - Living Documentation

This module demonstrates best practices for building APIs with FastAPI through
narrative-driven, executable examples. It serves as both working code and 
educational documentation.

Key concepts demonstrated:
- API design and organization
- Authentication and security
- Dependency injection
- Validation with Pydantic
- Documentation and OpenAPI
- Error handling
- Performance optimization

Run this file directly to see a narrated demonstration of FastAPI in action.
"""

import logging
import os
import time
import uuid
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Any, Union, Annotated

import uvicorn
from fastapi import FastAPI, Depends, HTTPException, status, Request, Path, Query
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, EmailStr, validator
from jose import JWTError, jwt
import contextlib

# Import our own modules for integration
try:
    from validation import DataValidationAndConfiguration
    from observability import LoggingObservabilityStandards
except ImportError:
    # When running standalone, create mock objects
    class DataValidationAndConfiguration:
        def __init__(self):
            pass
        
    class LoggingObservabilityStandards:
        def __init__(self):
            pass
        def create_basic_jsonl_logger(self):
            return logging.getLogger("fastapi_demo")


class FastAPIBestPractices:
    """
    Demonstrates FastAPI best practices through narrative explanation and working code.
    
    This class implements a demonstration FastAPI application that showcases
    recommended patterns and approaches. Each method is documented to explain
    not just what it does, but why it follows best practices.
    """
    
    def __init__(self):
        """
        Initialize the FastAPI demonstration application.
        
        Best practices shown:
        - Configurable title and version
        - Custom documentation URLs
        - Structured logging setup
        """
        print("=" * 80)
        print("ðŸš€ FASTAPI BEST PRACTICES DEMONSTRATION")
        print("=" * 80)
        print("This module demonstrates recommended patterns for FastAPI applications")
        print("while explaining the reasoning behind each practice.")
        
        self.secret_key = "demo-secret-key-replace-in-production"
        self.algorithm = "HS256"
        self.access_token_expire_minutes = 30
        
        # Integrate with the logging module
        self.logging_module = LoggingObservabilityStandards()
        self.logger = self.logging_module.create_basic_jsonl_logger()
        self.logger.info("Initializing FastAPI application")
        
        # Integrate with the validation module
        self.validation_module = DataValidationAndConfiguration()
        
        # Configure application-wide settings
        print("\nðŸ“‹ Initializing FastAPI application...")
        self.app = FastAPI(
            title="Demo API",
            description="API showcasing FastAPI best practices",
            version="1.0.0",
            docs_url="/docs",
            redoc_url="/redoc",
        )
        
        print("  âœ… Application initialized with title, description, and version")
        print("  âœ… Documentation configured at /docs and /redoc endpoints")
        
        # Set up authentication
        self.oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")
        print("  âœ… OAuth2 authentication scheme configured")
        
        # Configure CORS
        self._setup_cors()
        
        # Set up error handling
        self._setup_error_handling()
        
        # Set up routes
        self._setup_routes()
        
        # Set up the logging middleware (integrated with our logging module)
        self.setup_logging_middleware()
        
        print("  âœ… Application configuration complete")
        self.logger.info("FastAPI application initialized successfully")
    
    def _setup_cors(self):
        """
        Configure Cross-Origin Resource Sharing (CORS) middleware.
        
        Best practices shown:
        - Restricting origins to trusted domains
        - Environment-based configuration
        - Configuring allowed methods and headers
        """
        print("\nðŸ”’ Configuring CORS (Cross-Origin Resource Sharing)...")
        print("  â€¢ CORS prevents websites from making unauthorized requests to your API")
        print("  â€¢ In production, restrict origins to trusted domains")
        
        # In a real app, this would come from environment variables
        is_development = True
        
        allowed_origins = ["*"] if is_development else [
            "https://app.example.com", 
            "https://api.example.com"
        ]
        
        if is_development:
            print("  âš ï¸ DEVELOPMENT MODE: Allowing all origins (*)")
            print("  âš ï¸ This should NEVER be done in production")
        else:
            print(f"  âœ… PRODUCTION MODE: Restricting origins to: {', '.join(allowed_origins)}")
        
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=allowed_origins,
            allow_credentials=True,
            allow_methods=["GET", "POST", "PUT", "DELETE"],
            allow_headers=["*"],
        )
        
        print("  âœ… CORS middleware configured")
    
    def _setup_error_handling(self):
        """
        Configure global exception handling.
        
        Best practices shown:
        - Consistent error responses
        - Structured error logging
        - Hiding implementation details from clients
        """
        print("\nðŸ› ï¸ Setting up global error handling...")
        print("  â€¢ Centralizes error handling across the application")
        print("  â€¢ Provides consistent error responses")
        print("  â€¢ Logs exceptions while hiding sensitive details from client")
        
        @self.app.exception_handler(Exception)
        async def global_exception_handler(request: Request, exc: Exception):
            """Global exception handler for all unhandled exceptions."""
            # Here we would log to a structured logging system
            print(f"  âŒ [ERROR] Unhandled exception: {str(exc)}")
            print(f"  âŒ [ERROR] Path: {request.url.path}, Method: {request.method}")
            
            # Return a sanitized response to the client
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"detail": "Internal server error"}
            )
        
        print("  âœ… Global exception handler configured")
    
    def _setup_routes(self):
        """
        Configure API routes.
        
        Best practices shown:
        - Logical route organization
        - Health check endpoint
        - Authentication endpoints
        - Resource endpoints with proper HTTP methods
        """
        print("\nðŸ”Œ Setting up API routes...")
        print("  â€¢ Organized by resource and purpose")
        print("  â€¢ Using appropriate HTTP methods for actions")
        print("  â€¢ Including monitoring endpoints")
        
        # Health check endpoint
        @self.app.get("/health", tags=["monitoring"])
        async def health_check():
            """Health check endpoint for monitoring."""
            return {
                "status": "healthy",
                "version": "1.0.0",
                "timestamp": datetime.now().isoformat()
            }
        
        # Authentication endpoints
        @self.app.post("/token", response_model=self.Token, tags=["auth"])
        async def login(form_data: Annotated[OAuth2PasswordRequestForm, Depends()]):
            """OAuth2 compatible token login, returns JWT token."""
            user = self._authenticate_user(form_data.username, form_data.password)
            if not user:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Incorrect username or password",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            access_token = self._create_access_token(
                data={"sub": user.username}
            )
            return self.Token(access_token=access_token)
        
        # User endpoints
        @self.app.get("/users/me", response_model=self.User, tags=["users"])
        async def read_users_me(current_user: Annotated[self.User, Depends(self.get_current_user)]):
            """Get current user information."""
            return current_user
        
        # Item endpoints
        @self.app.get("/items", response_model=List[self.Item], tags=["items"])
        async def list_items(
            current_user: Annotated[self.User, Depends(self.get_current_user)],
            skip: Annotated[int, Query(ge=0, description="Skip N items")] = 0,
            limit: Annotated[int, Query(ge=1, le=100, description="Limit to N items")] = 10,
            tag: Optional[str] = None
        ):
            """
            Get a list of items with pagination support.
            
            - **skip**: Number of items to skip (for pagination)
            - **limit**: Maximum number of items to return
            - **tag**: Optional filter by tag
            """
            items = self._get_items(skip=skip, limit=limit, tag=tag)
            return items
        
        @self.app.post("/items", response_model=self.Item, status_code=201, tags=["items"])
        async def create_item(
            item: self.ItemCreate,
            current_user: Annotated[self.User, Depends(self.get_current_user)]
        ):
            """Create a new item (requires authentication)."""
            return self._create_item(item=item, user_id=current_user.id)
        
        @self.app.get(
            "/items/{item_id}", 
            response_model=self.Item, 
            tags=["items"],
            responses={404: {"description": "Item not found"}}
        )
        async def get_item(
            item_id: Annotated[int, Path(title="The ID of the item to get", ge=1)]
        ):
            """Get a specific item by ID."""
            item = self._get_item_by_id(item_id=item_id)
            if item is None:
                raise HTTPException(status_code=404, detail="Item not found")
            return item
        
        @self.app.put("/items/{item_id}", response_model=self.Item, tags=["items"])
        async def update_item(
            item_id: int,
            item: self.ItemCreate,
            current_user: Annotated[self.User, Depends(self.get_current_user)]
        ):
            """Update an item (requires authentication)."""
            existing_item = self._get_item_by_id(item_id=item_id)
            if existing_item is None:
                raise HTTPException(status_code=404, detail="Item not found")
            
            # Check ownership (optional)
            if existing_item.owner_id != current_user.id:
                raise HTTPException(status_code=403, detail="Not enough permissions")
                
            return self._update_item(item_id=item_id, item=item)
        
        @self.app.delete("/items/{item_id}", status_code=204, tags=["items"])
        async def delete_item(
            item_id: int,
            current_user: Annotated[self.User, Depends(self.get_current_user)]
        ):
            """
            Delete an item (requires authentication).
            
            Returns 204 No Content on success.
            """
            existing_item = self._get_item_by_id(item_id=item_id)
            if existing_item is None:
                raise HTTPException(status_code=404, detail="Item not found")
            
            # Check ownership (optional)
            if existing_item.owner_id != current_user.id:
                raise HTTPException(status_code=403, detail="Not enough permissions")
                
            self._delete_item(item_id=item_id)
            return None  # 204 No Content
        
        print("  âœ… API routes configured")
        print("  â€¢ GET /health - Health check endpoint")
        print("  â€¢ POST /token - Authentication endpoint")
        print("  â€¢ GET /users/me - Current user information")
        print("  â€¢ GET /items - List items with pagination")
        print("  â€¢ POST /items - Create a new item")
        print("  â€¢ GET /items/{item_id} - Get a specific item")
        print("  â€¢ PUT /items/{item_id} - Update an item")
        print("  â€¢ DELETE /items/{item_id} - Delete an item")
    
    # --- Pydantic Models ---
    
    class Token(BaseModel):
        """JWT token response model."""
        access_token: str
        token_type: str = "bearer"
    
    class User(BaseModel):
        """User model with basic information."""
        id: int
        username: str
        email: EmailStr
        is_active: bool = True
        
        class Config:
            from_attributes = True
    
    class UserCreate(BaseModel):
        """Model for creating a new user."""
        username: str = Field(..., min_length=3, max_length=50)
        email: EmailStr
        password: str = Field(..., min_length=8)
    
    class ItemBase(BaseModel):
        """Base item information."""
        name: str = Field(..., min_length=1, max_length=100, description="Name of the item")
        description: Optional[str] = Field(None, max_length=1000, description="Optional item description")
        price: float = Field(..., gt=0, description="Price must be greater than zero")
        tags: List[str] = Field(default_factory=list, description="List of item tags")
    
    class ItemCreate(ItemBase):
        """Model for creating a new item."""
        pass
    
    class Item(ItemBase):
        """Model for item responses."""
        id: int
        owner_id: int
        created_at: datetime
        
        class Config:
            from_attributes = True
    
    # --- Authentication methods ---
    
    def _authenticate_user(self, username: str, password: str) -> Optional[User]:
        """
        Authenticate a user by username and password.
        
        In a real application, this would check against a database.
        For this demo, we use a hardcoded user.
        """
        # Mock database lookup - in a real app, this would query a database
        if username == "testuser" and password == "password":
            return self.User(
                id=1,
                username="testuser",
                email="test@example.com",
                is_active=True
            )
        return None
    
    def _create_access_token(self, data: Dict[str, Any]) -> str:
        """
        Create a JWT access token with an expiration time.
        
        Best practices shown:
        - Token expiration
        - Secure signing algorithm
        - Claims-based token content
        """
        to_encode = data.copy()
        expire = datetime.now(timezone.utc) + timedelta(minutes=self.access_token_expire_minutes)
        to_encode.update({"exp": expire})
        
        # In a real app, SECRET_KEY would be loaded from an environment variable
        encoded_jwt = jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
        return encoded_jwt
    
    async def get_current_user(self, token: Annotated[str, Depends(oauth2_scheme)]) -> User:
        """
        Validate the access token and return the current user.
        
        Best practices shown:
        - Token validation
        - Specific error messages
        - Authentication headers in exceptions
        """
        credentials_exception = HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
        
        try:
            # Decode the JWT token
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            username: str = payload.get("sub")
            if username is None:
                raise credentials_exception
            
            # In a real app, this would lookup the user in a database
            if username == "testuser":
                return self.User(
                    id=1,
                    username="testuser",
                    email="test@example.com",
                    is_active=True
                )
            else:
                raise credentials_exception
        except JWTError:
            raise credentials_exception
    
    # --- Demo data methods ---
    
    def _get_items(self, skip: int = 0, limit: int = 10, tag: Optional[str] = None) -> List[Item]:
        """Mock database query for items."""
        # This would query a database in a real application
        items = [
            self.Item(
                id=1,
                name="Item 1",
                description="Description for Item 1",
                price=19.99,
                tags=["electronics", "gadgets"],
                owner_id=1,
                created_at=datetime.now() - timedelta(days=5)
            ),
            self.Item(
                id=2,
                name="Item 2",
                description="Description for Item 2",
                price=29.99,
                tags=["clothing", "accessories"],
                owner_id=1,
                created_at=datetime.now() - timedelta(days=3)
            ),
            self.Item(
                id=3,
                name="Item 3",
                description="Description for Item 3",
                price=39.99,
                tags=["electronics", "accessories"],
                owner_id=1,
                created_at=datetime.now() - timedelta(days=1)
            )
        ]
        
        # Apply tag filter if specified
        if tag:
            items = [item for item in items if tag in item.tags]
        
        # Apply pagination
        return items[skip:skip+limit]
    
    def _get_item_by_id(self, item_id: int) -> Optional[Item]:
        """Mock database query for a specific item."""
        items = self._get_items(limit=100)
        for item in items:
            if item.id == item_id:
                return item
        return None
    
    def _create_item(self, item: ItemCreate, user_id: int) -> Item:
        """Mock database creation for an item."""
        # In a real app, this would insert into a database
        return self.Item(
            id=4,  # Would be generated by the database
            **item.dict(),
            owner_id=user_id,
            created_at=datetime.now()
        )
    
    def _update_item(self, item_id: int, item: ItemCreate) -> Item:
        """Mock database update for an item."""
        # In a real app, this would update a database record
        existing_item = self._get_item_by_id(item_id)
        if existing_item:
            # Update fields
            updated_item = self.Item(
                id=existing_item.id,
                **item.dict(),
                owner_id=existing_item.owner_id,
                created_at=existing_item.created_at
            )
            return updated_item
        raise HTTPException(status_code=404, detail="Item not found")
    
    def _delete_item(self, item_id: int) -> None:
        """Mock database deletion for an item."""
        # In a real app, this would delete from a database
        pass
    
    # --- Logging middleware ---
    
    def setup_logging_middleware(self):
        """
        Configure request logging middleware with structured logging.
        
        Best practices shown:
        - Structured logging for every request
        - Performance timing
        - Correlation IDs for request tracing
        - Exception capturing
        """
        print("\nðŸ“ Setting up request logging middleware...")
        print("  â€¢ Logs every request with structured data")
        print("  â€¢ Includes timing information")
        print("  â€¢ Generates correlation IDs for request tracing")
        
        @self.app.middleware("http")
        async def log_requests(request: Request, call_next):
            """Log request details, timing, and response status."""
            # Generate a unique ID for this request
            request_id = str(uuid.uuid4())
            
            # Store in the request state for access in route handlers
            request.state.request_id = request_id
            
            # Log the start of the request using our structured logger
            self.logger.info(
                "Request started",
                request_id=request_id,
                method=request.method,
                url=str(request.url),
                client=request.client.host if request.client else None
            )
            
            # Time the request
            start_time = time.time()
            
            try:
                # Process the request
                response = await call_next(request)
                
                # Calculate processing time
                process_time = time.time() - start_time
                
                # Add timing header
                response.headers["X-Process-Time"] = str(process_time)
                
                # Log the completed request
                self.logger.info(
                    "Request completed",
                    request_id=request_id,
                    method=request.method,
                    url=str(request.url),
                    status_code=response.status_code,
                    process_time=process_time
                )
                
                return response
                
            except Exception as e:
                # Log exceptions
                process_time = time.time() - start_time
                self.logger.error(
                    "Request failed",
                    request_id=request_id,
                    method=request.method,
                    url=str(request.url),
                    error=str(e),
                    process_time=process_time,
                    exc_info=True
                )
                raise
                
        print("  âœ… Request logging middleware configured")
    
    def start_server(self, host: str = "127.0.0.1", port: int = 8000):
        """
        Start the FastAPI server for demonstration purposes.
        
        Best practices shown:
        - Configurable host and port
        - Proper uvicorn configuration
        - Graceful shutdown
        """
        print("\nðŸš€ Starting FastAPI server...")
        print(f"  â€¢ Host: {host}")
        print(f"  â€¢ Port: {port}")
        print("  â€¢ OpenAPI documentation will be available at /docs")
        print("  â€¢ ReDoc documentation will be available at /redoc")
        print("\n  Press Ctrl+C to stop the server")
        
        # Set up the logging middleware before starting
        self.setup_logging_middleware()
        
        # In a real application, this would use a proper production server setup
        uvicorn.run(self.app, host=host, port=port)
    
    def run_demo(self):
        """
        Run a demo showcasing various FastAPI features.
        
        This method demonstrates:
        - API structure and organization
        - Authentication flow
        - Request/response cycle
        - Error handling
        """
        print("\n" + "=" * 80)
        print("ðŸŽ® FASTAPI INTERACTIVE DEMO")
        print("=" * 80)
        print("\nThis demo will guide you through the key features of FastAPI")
        print("and showcase best practices for building robust APIs.")
        
        print("\nðŸ“‹ FEATURES OVERVIEW:")
        print("  â€¢ Automatic OpenAPI documentation")
        print("  â€¢ Pydantic model validation")
        print("  â€¢ Dependency injection system")
        print("  â€¢ JWT authentication")
        print("  â€¢ Type hints throughout")
        print("  â€¢ Automatic serialization/deserialization")
        
        print("\nðŸ”„ TYPICAL API FLOWS:")
        
        print("\n1. AUTHENTICATION FLOW")
        print("   â†“ Client sends credentials to /token endpoint")
        print("   â†“ Server validates credentials and generates JWT")
        print("   â†“ Client includes JWT in Authorization header")
        print("   â†“ Server validates JWT for protected endpoints")
        
        print("\n2. RESOURCE CREATION FLOW")
        print("   â†“ Client sends authenticated POST request with data")
        print("   â†“ Server validates request data with Pydantic")
        print("   â†“ Server creates resource and returns 201 Created")
        print("   â†“ Response includes the created resource with ID")
        
        print("\n3. ERROR HANDLING FLOW")
        print("   â†“ Client sends invalid request")
        print("   â†“ Server validates and returns appropriate error")
        print("   â†“ Response includes status code and error details")
        print("   â†“ Client can use error information to fix request")
        
        print("\nðŸ” To explore the full API:")
        print("  1. Start the server with .start_server()")
        print("  2. Open http://localhost:8000/docs in your browser")
        print("  3. Use the interactive documentation to test endpoints")
        print("  4. Try authenticating with username 'testuser' and password 'password'")
        
        print("\n" + "=" * 80)
        print("FastAPI makes it easy to build production-ready APIs with Python")
        print("For more information, visit: https://fastapi.tiangolo.com/")
        print("=" * 80)
        
        # Optionally start the server automatically
        start_server = input("\nStart the demo server now? (y/n): ").strip().lower()
        if start_server == 'y':
            self.start_server()


if __name__ == "__main__":
    # Create and run the demo
    demo = FastAPIBestPractices()
    demo.run_demo()./pydantic_best_practice.py
#!/usr/bin/env python3
"""
Pydantic Data Validation & Configuration - Living Documentation

This module demonstrates best practices for data validation and configuration 
management using Pydantic. It serves as both working code and educational
documentation with interactive examples.

Key concepts demonstrated:
- Model definition and validation
- Configuration management
- Field constraints and validators
- Serialization and deserialization
- Error handling
- Integration patterns

Run this file directly to see a narrated demonstration of Pydantic in action.
"""

import json
import os
import re
import sys
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Union, Any, TypeVar, Literal, Annotated
from uuid import UUID, uuid4
from pathlib import Path
import contextlib


class PydanticBestPractices:
    """
    Demonstrates Pydantic best practices through narrative explanation and working code.
    
    This class implements a series of examples that showcase recommended patterns
    for using Pydantic to validate and manage data in Python applications.
    """
    
    def __init__(self):
        """Initialize the demonstration."""
        print("=" * 80)
        print("ðŸ” PYDANTIC DATA VALIDATION & CONFIGURATION BEST PRACTICES")
        print("=" * 80)
        print("\nThis module demonstrates how to effectively use Pydantic for")
        print("data validation, configuration management, and ensuring type safety.")
        
        # Check Pydantic version to ensure we're using v2+
        try:
            import pydantic
            version = pydantic.__version__
            major_version = int(version.split('.')[0])
            if major_version < 2:
                print(f"\nâš ï¸ WARNING: You are using Pydantic v{version}.")
                print("This demonstration requires Pydantic v2.0.0 or higher.")
                print("Please upgrade with: pip install -U pydantic>=2.0.0")
                sys.exit(1)
            else:
                print(f"\nâœ… Using Pydantic v{version}")
        except ImportError:
            print("\nâŒ ERROR: Pydantic is not installed.")
            print("Please install with: pip install pydantic>=2.0.0")
            sys.exit(1)

    def demonstrate_basic_models(self):
        """
        Demonstrate the definition and usage of basic Pydantic models.
        
        Best practices shown:
        - Type annotations for automatic validation
        - Field constraints for data integrity
        - Custom validators for complex rules
        - Immutable models to prevent accidental state changes
        """
        from pydantic import BaseModel, Field, field_validator, EmailStr
        from pydantic_core import PydanticCustomError
        
        print("\n" + "-" * 80)
        print("ðŸ“˜ BASIC MODEL DEFINITION & VALIDATION")
        print("-" * 80)
        print("Best Practice: Use Pydantic models instead of dictionaries for all structured data")
        print("Benefits: Runtime validation, type safety, self-documenting code")
        
        # Define a basic user model
        class User(BaseModel):
            """User model with validation."""
            # Best Practice: Make models immutable by default
            model_config = {"frozen": True}
            
            id: int = Field(..., gt=0, description="Unique user identifier")
            email: str
            is_active: bool = True
            created_at: datetime = Field(default_factory=datetime.utcnow)
            
            # Custom validator to ensure email format
            @field_validator("email")
            @classmethod
            def validate_email(cls, value: str) -> str:
                if "@" not in value:
                    # Use PydanticCustomError for specific error types
                    raise PydanticCustomError(
                        "value_error",
                        "Email address must contain an '@' symbol",
                        {"value": value}
                    )
                return value.lower()  # Normalize email to lowercase
        
        print("\nðŸ“ Example Model: User")
        print(f"Fields:")
        print(f"  â€¢ id: int (required, > 0)")
        print(f"  â€¢ email: str (required, must contain @)")
        print(f"  â€¢ is_active: bool (default: True)")
        print(f"  â€¢ created_at: datetime (default: current UTC time)")
        
        print("\nðŸ” Demonstration: Creating valid model instances")
        # Valid user creation
        try:
            user = User(id=1, email="user@example.com")
            print(f"  âœ… Valid user created: {user}")
            
            # Try to modify the immutable model
            try:
                user.email = "new@example.com"
                print(f"  âŒ This line should not execute - model is mutable!")
            except Exception as e:
                print(f"  âœ… Cannot modify frozen model: {type(e).__name__}: {str(e)}")
        except Exception as e:
            print(f"  âŒ Unexpected error: {type(e).__name__}: {str(e)}")
        
        print("\nðŸ” Demonstration: Validation prevents invalid data")
        # Invalid ID (must be > 0)
        try:
            User(id=0, email="user@example.com")
            print(f"  âŒ This line should not execute - id validation failed!")
        except Exception as e:
            print(f"  âœ… Validation caught invalid ID: {str(e)}")
        
        # Invalid email (must contain @)
        try:
            User(id=1, email="invalid-email")
            print(f"  âŒ This line should not execute - email validation failed!")
        except Exception as e:
            print(f"  âœ… Validation caught invalid email: {str(e)}")
        
        # Next, demonstrate serialization
        print("\nðŸ”„ Demonstration: Model serialization")
        user = User(id=1, email="user@example.com")
        
        # Proper way to serialize to dict
        user_dict = user.model_dump()
        print(f"  âœ… Serialized to dict: {json.dumps(user_dict, default=str)}")
        
        # Proper way to serialize to JSON
        user_json = user.model_dump_json()
        print(f"  âœ… Serialized to JSON: {user_json}")
        
        # Best practices for model serialization
        print("\nâ­ Best Practices for Serialization:")
        print("  â€¢ Always use .model_dump() instead of dict(model)")
        print("  â€¢ Always use .model_dump_json() for JSON serialization")
        print("  â€¢ Configure model_dump with include/exclude for field filtering")
        print("  â€¢ Use exclude_none=True to omit None values when appropriate")
        
        print("\nâš ï¸ Common Pitfalls to Avoid:")
        print("  â€¢ Manually creating dictionaries from model attributes")
        print("  â€¢ Using json.dumps() directly on model instances")
        print("  â€¢ Bypassing validation with direct dictionary manipulation")
        
        return User  # Return for use in later examples

    def demonstrate_config_management(self):
        """
        Demonstrate configuration management using Pydantic Settings.
        
        Best practices shown:
        - Centralized configuration with environment variables
        - Validation of configuration values
        - Type conversion and defaults
        - .env file support
        """
        from pydantic import BaseModel, Field, PostgresDsn
        from pydantic_settings import BaseSettings, SettingsConfigDict
        from functools import lru_cache
        
        print("\n" + "-" * 80)
        print("âš™ï¸ CONFIGURATION MANAGEMENT")
        print("-" * 80)
        print("Best Practice: Use Pydantic Settings for all application configuration")
        print("Benefits: Environment variable integration, type validation, centralized config")
        
        # Create a temporary .env file for demonstration
        env_content = """
        # Application settings
        DEBUG=true
        API_KEY=demo-api-key
        DATABASE_URL=postgresql://user:password@localhost:5432/demo
        LOG_LEVEL=INFO
        MAX_CONNECTIONS=10
        ALLOWED_HOSTS=localhost,127.0.0.1
        """
        
        env_file = Path(".env.demo")
        with open(env_file, "w") as f:
            f.write(env_content)
        
        print(f"\nðŸ“ Created demo .env file: {env_file}")
        print("Contents (would normally contain sensitive information):")
        for line in env_content.strip().split("\n"):
            if line.strip() and not line.strip().startswith("#"):
                print(f"  {line.strip()}")
        
        # Define a settings class
        class LogLevel(str, Enum):
            """Valid log levels."""
            DEBUG = "DEBUG"
            INFO = "INFO"
            WARNING = "WARNING"
            ERROR = "ERROR"
            CRITICAL = "CRITICAL"
        
        class Settings(BaseSettings):
            """Application settings with validation."""
            model_config = SettingsConfigDict(
                env_file=".env.demo",      # Load from custom .env file
                case_sensitive=False,      # Environment variables are case-insensitive
                extra="ignore",            # Ignore extra fields from environment
                env_file_encoding="utf-8", # Specify file encoding
            )
            
            # Basic settings with validation
            debug: bool = Field(default=False, description="Enable debug mode")
            api_key: str = Field(..., description="API key for external services")
            log_level: LogLevel = Field(default=LogLevel.INFO, description="Application log level")
            
            # Database connection using special Pydantic types
            database_url: PostgresDsn = Field(
                ..., 
                description="Database connection string"
            )
            
            # Numeric value with constraints
            max_connections: int = Field(
                default=5, 
                ge=1, 
                le=100, 
                description="Maximum number of database connections"
            )
            
            # List from comma-separated string
            allowed_hosts: List[str] = Field(
                default_factory=lambda: ["localhost"],
                description="List of allowed hosts"
            )
            
            # Computed property based on other settings
            @property
            def is_production(self) -> bool:
                """Determine if this is a production environment."""
                return not self.debug and "localhost" not in self.allowed_hosts
        
        # Use lru_cache for efficient access to the settings
        @lru_cache
        def get_settings() -> Settings:
            """Returns cached application settings."""
            return Settings()
        
        print("\nðŸ” Demonstration: Loading settings from environment")
        try:
            settings = get_settings()
            print("  âœ… Settings loaded successfully")
            print(f"  â€¢ Debug mode: {settings.debug}")
            print(f"  â€¢ API key: {settings.api_key}")
            print(f"  â€¢ Database URL: {settings.database_url}")
            print(f"  â€¢ Log level: {settings.log_level}")
            print(f"  â€¢ Max connections: {settings.max_connections}")
            print(f"  â€¢ Allowed hosts: {settings.allowed_hosts}")
            print(f"  â€¢ Is production: {settings.is_production}")
        except Exception as e:
            print(f"  âŒ Error loading settings: {type(e).__name__}: {str(e)}")
        
        # Clean up the demo .env file
        env_file.unlink()
        print(f"\nðŸ§¹ Removed demo .env file")
        
        print("\nâ­ Best Practices for Configuration:")
        print("  â€¢ Create a single Settings class for all application configuration")
        print("  â€¢ Use environment variables for deployment-specific settings")
        print("  â€¢ Validate configuration values at application startup")
        print("  â€¢ Use lru_cache to avoid repeatedly parsing environment variables")
        print("  â€¢ Handle sensitive values carefully (don't log them)")
        
        return Settings  # Return for use in later examples

    def demonstrate_nested_models(self):
        """
        Demonstrate nested models and relationships.
        
        Best practices shown:
        - Model composition
        - List fields with validators
        - Default factories for complex defaults
        - Cross-field validation
        """
        from pydantic import BaseModel, Field, field_validator, model_validator, computed_field
        
        print("\n" + "-" * 80)
        print("ðŸ§© NESTED MODELS & RELATIONSHIPS")
        print("-" * 80)
        print("Best Practice: Use model composition for complex data structures")
        print("Benefits: Better organization, reusable components, structured validation")
        
        # Define nested models for a richer domain model
        class Address(BaseModel):
            """Physical address model."""
            model_config = {"frozen": True}
            
            street: str
            city: str
            state: Optional[str] = None
            country: str
            postal_code: str
            is_primary: bool = False
        
        class Contact(BaseModel):
            """Contact information model."""
            email: str
            phone: Optional[str] = None
            
            @field_validator("email")
            @classmethod
            def validate_email(cls, value: str) -> str:
                if "@" not in value:
                    raise ValueError("Email must contain @ symbol")
                return value.lower()
            
            @field_validator("phone")
            @classmethod
            def validate_phone(cls, value: Optional[str]) -> Optional[str]:
                if value is None:
                    return None
                    
                # Remove common formatting characters
                digits_only = re.sub(r'[^0-9]', '', value)
                if len(digits_only) < 10:
                    raise ValueError("Phone number must have at least 10 digits")
                return digits_only
        
        class UserProfile(BaseModel):
            """Extended user profile information."""
            bio: Optional[str] = None
            avatar_url: Optional[str] = None
            preferences: Dict[str, str] = Field(default_factory=dict)
        
        class User(BaseModel):
            """User model with nested components."""
            id: UUID = Field(default_factory=uuid4)
            username: str
            created_at: datetime = Field(default_factory=datetime.utcnow)
            contact: Contact
            profile: UserProfile = Field(default_factory=UserProfile)
            addresses: List[Address] = Field(default_factory=list)
            
            @model_validator(mode='after')
            def ensure_primary_address(self) -> 'User':
                """Ensure there is exactly one primary address if addresses exist."""
                if not self.addresses:
                    return self
                    
                primary_addresses = [addr for addr in self.addresses if addr.is_primary]
                if not primary_addresses:
                    # Make the first address primary if none are marked
                    addresses = list(self.addresses)  # Create a mutable copy
                    addresses[0] = Address(**{**addresses[0].model_dump(), "is_primary": True})
                    object.__setattr__(self, 'addresses', addresses)
                elif len(primary_addresses) > 1:
                    raise ValueError("Only one address can be marked as primary")
                
                return self
            
            @computed_field
            @property
            def primary_address(self) -> Optional[Address]:
                """Return the primary address if it exists."""
                for addr in self.addresses:
                    if addr.is_primary:
                        return addr
                return None
        
        print("\nðŸ“ Example Model Hierarchy:")
        print("User")
        print("â”œâ”€â”€ id: UUID (auto-generated)")
        print("â”œâ”€â”€ username: str")
        print("â”œâ”€â”€ created_at: datetime (auto-generated)")
        print("â”œâ”€â”€ contact: Contact")
        print("â”‚   â”œâ”€â”€ email: str (validated)")
        print("â”‚   â””â”€â”€ phone: Optional[str] (validated)")
        print("â”œâ”€â”€ profile: UserProfile")
        print("â”‚   â”œâ”€â”€ bio: Optional[str]")
        print("â”‚   â”œâ”€â”€ avatar_url: Optional[str]")
        print("â”‚   â””â”€â”€ preferences: Dict[str, str]")
        print("â””â”€â”€ addresses: List[Address]")
        print("    â”œâ”€â”€ street: str")
        print("    â”œâ”€â”€ city: str")
        print("    â”œâ”€â”€ state: Optional[str]")
        print("    â”œâ”€â”€ country: str")
        print("    â”œâ”€â”€ postal_code: str")
        print("    â””â”€â”€ is_primary: bool")
        
        print("\nðŸ” Demonstration: Creating a user with nested models")
        
        # Create a user with nested models
        try:
            user = User(
                username="johndoe",
                contact=Contact(
                    email="john.doe@example.com",
                    phone="(555) 123-4567"
                ),
                addresses=[
                    Address(
                        street="123 Main St",
                        city="Anytown",
                        state="CA",
                        country="US",
                        postal_code="12345",
                        is_primary=True
                    ),
                    Address(
                        street="456 Market St",
                        city="Othertown",
                        state="NY",
                        country="US",
                        postal_code="67890"
                    )
                ]
            )
            
            print("  âœ… User created successfully")
            print(f"  â€¢ Username: {user.username}")
            print(f"  â€¢ Contact email: {user.contact.email}")
            print(f"  â€¢ Contact phone: {user.contact.phone}")
            print(f"  â€¢ Number of addresses: {len(user.addresses)}")
            print(f"  â€¢ Primary address: {user.primary_address.city}, {user.primary_address.state}" if user.primary_address else "None")
        except Exception as e:
            print(f"  âŒ Error creating user: {type(e).__name__}: {str(e)}")
        
        print("\nðŸ” Demonstration: Cross-field validation")
        
        # Create a user with multiple primary addresses (should fail)
        try:
            user = User(
                username="janedoe",
                contact=Contact(
                    email="jane.doe@example.com"
                ),
                addresses=[
                    Address(
                        street="123 Main St",
                        city="Anytown",
                        country="US",
                        postal_code="12345",
                        is_primary=True
                    ),
                    Address(
                        street="456 Market St",
                        city="Othertown",
                        country="US",
                        postal_code="67890",
                        is_primary=True  # Second primary address - should fail
                    )
                ]
            )
            print("  âŒ This line should not execute - validation should fail!")
        except Exception as e:
            print(f"  âœ… Validation caught multiple primary addresses: {type(e).__name__}: {str(e)}")
        
        print("\nðŸ” Demonstration: Automatic primary address selection")
        
        # Create a user with no primary address (first should be marked as primary)
        try:
            user = User(
                username="samsmith",
                contact=Contact(
                    email="sam.smith@example.com"
                ),
                addresses=[
                    Address(
                        street="123 Main St",
                        city="Anytown",
                        country="US",
                        postal_code="12345",
                        is_primary=False  # Not primary
                    ),
                    Address(
                        street="456 Market St",
                        city="Othertown",
                        country="US",
                        postal_code="67890",
                        is_primary=False  # Not primary
                    )
                ]
            )
            
            print("  âœ… User created successfully")
            print(f"  â€¢ First address is now primary: {user.addresses[0].is_primary}")
            print(f"  â€¢ Second address is still not primary: {user.addresses[1].is_primary}")
            print(f"  â€¢ Primary address: {user.primary_address.city}, {user.primary_address.country}")
        except Exception as e:
            print(f"  âŒ Error creating user: {type(e).__name__}: {str(e)}")
        
        print("\nâ­ Best Practices for Nested Models:")
        print("  â€¢ Break complex models into smaller, focused components")
        print("  â€¢ Use model composition to build rich domain models")
        print("  â€¢ Implement cross-field validation with model_validator")
        print("  â€¢ Use default_factory for complex default values")
        print("  â€¢ Add computed_field properties for derived values")
        
        return User  # Return for use in later examples

    def demonstrate_model_evolution(self):
        """
        Demonstrate model evolution and versioning strategies.
        
        Best practices shown:
        - Model versioning for backward compatibility
        - Creating new model versions while maintaining old ones
        - Migration between model versions
        """
        from pydantic import BaseModel, Field, root_validator
        from typing import Literal, Optional, List, Dict, Union, Any
        
        print("\n" + "-" * 80)
        print("ðŸ”„ MODEL EVOLUTION & VERSIONING")
        print("-" * 80)
        print("Best Practice: Version your models for API stability")
        print("Benefits: Backward compatibility, controlled evolution, clear client expectations")
        
        # Define a versioned model hierarchy
        class ProductBase(BaseModel):
            """Base product fields common to all versions."""
            id: int
            name: str
        
        class ProductV1(ProductBase):
            """Version 1 of the Product model."""
            model_version: Literal["v1"] = "v1"
            price: float
            description: Optional[str] = None
            
            class Config:
                extra = "forbid"  # Prevent extra fields
        
        class ProductV2(ProductBase):
            """Version 2 of the Product model with extended fields."""
            model_version: Literal["v2"] = "v2"
            price: Dict[str, float]  # Now a dictionary of currency -> price
            description: str  # Now required
            category: str  # New field
            tags: List[str] = Field(default_factory=list)  # New field
            
            class Config:
                extra = "forbid"
        
        # Define a version-agnostic product type
        ProductAny = Union[ProductV1, ProductV2]
        
        # Migration function to upgrade from v1 to v2
        def migrate_product_v1_to_v2(product_v1: ProductV1) -> ProductV2:
            """Migrate a v1 product to v2 format."""
            # Extract base fields
            base_data = product_v1.model_dump()
            
            # Remove v1-specific fields
            base_data.pop("model_version")
            price = base_data.pop("price")
            
            # Add v2-specific fields
            return ProductV2(
                **base_data,
                price={"USD": price},  # Convert price to dictionary
                description=product_v1.description or "No description available",  # Ensure description is not None
                category="Uncategorized"  # Default category for migrated products
            )
        
        print("\nðŸ“ Versioned Model Example: Product")
        print("\nProductV1:")
        print("â”œâ”€â”€ id: int")
        print("â”œâ”€â”€ name: str")
        print("â”œâ”€â”€ model_version: Literal['v1']")
        print("â”œâ”€â”€ price: float")
        print("â””â”€â”€ description: Optional[str]")
        
        print("\nProductV2:")
        print("â”œâ”€â”€ id: int")
        print("â”œâ”€â”€ name: str")
        print("â”œâ”€â”€ model_version: Literal['v2']")
        print("â”œâ”€â”€ price: Dict[str, float]")
        print("â”œâ”€â”€ description: str (now required)")
        print("â”œâ”€â”€ category: str (new field)")
        print("â””â”€â”€ tags: List[str] (new field)")
        
        print("\nðŸ” Demonstration: Creating models of different versions")
        
        # Create a v1 product
        product_v1 = ProductV1(
            id=1,
            name="Basic Widget",
            price=19.99
        )
        print(f"  âœ… ProductV1 created: {product_v1.model_dump_json()}")
        
        # Create a v2 product
        product_v2 = ProductV2(
            id=2,
            name="Advanced Widget",
            price={"USD": 29.99, "EUR": 26.99},
            description="An advanced widget with multiple features",
            category="Widgets",
            tags=["advanced", "featured"]
        )
        print(f"  âœ… ProductV2 created: {product_v2.model_dump_json()}")
        
        print("\nðŸ” Demonstration: Migrating from v1 to v2")
        
        # Migrate a v1 product to v2
        migrated_product = migrate_product_v1_to_v2(product_v1)
        print(f"  âœ… Migrated product: {migrated_product.model_dump_json()}")
        
        print("\nðŸ” Demonstration: API versioning strategy")
        
        print("\nIn a REST API, you would typically use URL versioning:")
        print("  â€¢ /api/v1/products - Returns ProductV1 objects")
        print("  â€¢ /api/v2/products - Returns ProductV2 objects")
        
        print("\nOr set up version-specific routes in FastAPI:")
        print("  v1_router = APIRouter(prefix='/v1')")
        print("  v2_router = APIRouter(prefix='/v2')")
        print("  app.include_router(v1_router)")
        print("  app.include_router(v2_router)")
        
        print("\nâ­ Best Practices for Model Versioning:")
        print("  â€¢ Include explicit version field in models (model_version)")
        print("  â€¢ Never modify existing model versions in breaking ways")
        print("  â€¢ Create new model versions for significant changes")
        print("  â€¢ Provide migration utilities between versions")
        print("  â€¢ Version your APIs to match model versions")
        print("  â€¢ Set appropriate deprecation timelines for old versions")
        
        return {
            "v1": ProductV1,
            "v2": ProductV2,
            "migrate": migrate_product_v1_to_v2
        }  # Return for use in later examples

    def demonstrate_error_handling(self):
        """
        Demonstrate proper error handling with Pydantic.
        
        Best practices shown:
        - Custom error types
        - Structured error responses
        - Validation errors
        - Error formatting
        """
        from pydantic import BaseModel, Field, field_validator, ValidationError
        
        print("\n" + "-" * 80)
        print("âš ï¸ ERROR HANDLING & VALIDATION")
        print("-" * 80)
        print("Best Practice: Use structured error handling with Pydantic ValidationError")
        print("Benefits: Consistent error responses, detailed validation feedback, easier debugging")
        
        # Define a model with various validation rules
        class Product(BaseModel):
            """Product model with validation rules."""
            name: str = Field(..., min_length=3, max_length=50)
            price: float = Field(..., gt=0)
            sku: str = Field(..., pattern=r'^[A-Z]{2}\d{6}$')  # Format: XX123456
            stock: int = Field(..., ge=0)
            
            @field_validator("name")
            @classmethod
            def validate_name(cls, value: str) -> str:
                if value.lower() == "test":
                    raise ValueError("'test' is not a valid product name")
                return value.strip()
        
        # Define an error response model
        class ErrorDetail(BaseModel):
            """Details about a validation error."""
            loc: List[str]
            msg: str
            type: str
        
        class ErrorResponse(BaseModel):
            """Structured error response."""
            detail: List[ErrorDetail]
        
        print("\nðŸ“ Example Model: Product with Validation Rules")
        print("â”œâ”€â”€ name: str (3-50 chars, cannot be 'test')")
        print("â”œâ”€â”€ price: float (must be > 0)")
        print("â”œâ”€â”€ sku: str (must match pattern XX123456)")
        print("â””â”€â”€ stock: int (must be >= 0)")
        
        print("\nðŸ” Demonstration: Handling validation errors")
        
        # Function to create a product with error handling
        def create_product(data: Dict[str, Any]) -> Union[Product, ErrorResponse]:
            """Create a product with validation error handling."""
            try:
                return Product(**data)
            except ValidationError as e:
                return ErrorResponse(detail=[
                    ErrorDetail(
                        loc=list(map(str, error["loc"])),
                        msg=error["msg"],
                        type=error["type"]
                    )
                    for error in e.errors()
                ])
        
        # Valid product
        valid_data = {
            "name": "Wireless Headphones",
            "price": 99.99,
            "sku": "HX123456",
            "stock": 100
        }
        
        result = create_product(valid_data)
        if isinstance(result, Product):
            print(f"  âœ… Valid product created: {result.model_dump_json()}")
        else:
            print(f"  âŒ Unexpected validation error: {result.model_dump_json()}")
        
        # Invalid product with multiple errors
        invalid_data = {
            "name": "t",  # Too short
            "price": -10,  # Negative price
            "sku": "invalid",  # Invalid SKU format
            "stock": -5  # Negative stock
        }
        
        result = create_product(invalid_data)
        if isinstance(result, ErrorResponse):
            print(f"  âœ… Validation errors caught:")
            for error in result.detail:
                print(f"    â€¢ Field: {'.'.join(error.loc)}: {error.msg} ({error.type})")
        else:
            print(f"  âŒ Validation should have failed but didn't!")
        
        # Processing validation errors
        print("\nðŸ” Demonstration: Structured error handling in API context")
        
        def api_create_product(data: Dict[str, Any]) -> Dict[str, Any]:
            """Simulate API endpoint with proper error handling."""
            try:
                product = Product(**data)
                # In a real API, you would save to database here
                return {
                    "status": "success",
                    "data": product.model_dump(),
                    "code": 201  # Created
                }
            except ValidationError as e:
                return {
                    "status": "error",
                    "detail": e.errors(),
                    "code": 422  # Unprocessable Entity
                }
        
        # Invalid product
        response = api_create_product({
            "name": "test",  # Invalid name
            "price": 99.99,
            "sku": "HX123456",
            "stock": 100
        })
        
        print(f"  API Response Status: {response['status']}")
        print(f"  HTTP Status Code: {response['code']}")
        if response["status"] == "error":
            print("  Validation Errors:")
            for error in response["detail"]:
                print(f"    â€¢ Field: {'.'.join(map(str, error['loc']))}: {error['msg']}")
        
        print("\nâ­ Best Practices for Error Handling:")
        print("  â€¢ Use try/except blocks around model creation")
        print("  â€¢ Create structured error responses with ValidationError.errors()")
        print("  â€¢ Return appropriate HTTP status codes (422 for validation errors)")
        print("  â€¢ Keep a consistent error format across your API")
        print("  â€¢ Include enough detail to help clients fix their requests")
        
        return ErrorResponse  # Return for use in later examples

    def demonstrate_integration_patterns(self):
        """
        Demonstrate integration patterns with other systems.
        
        Best practices shown:
        - Integration with FastAPI
        - Integration with SQLAlchemy
        - Converting between different model types
        """
        from pydantic import BaseModel, Field, EmailStr, ConfigDict
        from typing import List, Optional, Dict, Any, ClassVar, Type
        from datetime import datetime
        
        print("\n" + "-" * 80)
        print("ðŸ”Œ INTEGRATION PATTERNS")
        print("-" * 80)
        print("Best Practice: Use consistent patterns for integrating with other systems")
        print("Benefits: Clean boundaries, type safety, centralized validation")
        
        # Mock SQLAlchemy model (simulated)
        class UserDB:
            """Simulated SQLAlchemy model."""
            __tablename__ = "users"
            
            id: int
            email: str
            is_active: bool
            hashed_password: str
            created_at: datetime
            
            def __init__(self, **kwargs):
                for key, value in kwargs.items():
                    setattr(self, key, value)
        
        # Pydantic models for the API layer
        class UserBase(BaseModel):
            """Base user fields."""
            email: EmailStr
            is_active: bool = True
        
        class UserCreate(UserBase):
            """Model for creating a new user."""
            password: str  # Plain text password only for request
            
            model_config = ConfigDict(extra="forbid")  # Reject extra fields
        
        class UserUpdate(BaseModel):
            """Model for updating an existing user."""
            email: Optional[EmailStr] = None
            is_active: Optional[bool] = None
            
            model_config = ConfigDict(extra="forbid")
        
        class UserInDB(UserBase):
            """Internal user model with hashed password."""
            id: int
            hashed_password: str
            created_at: datetime
            
            # Configure for ORM mode
            model_config = ConfigDict(from_attributes=True)
        
        class UserResponse(UserBase):
            """User model returned in API responses."""
            id: int
            created_at: datetime
            
            # Configure for ORM mode
            model_config = ConfigDict(from_attributes=True)
        
        # Service layer for user operations
        class UserService:
            """Service for user operations."""
            
            @staticmethod
            def create_user(user_create: UserCreate) -> UserInDB:
                """Create a new user."""
                # Hash the password (simulated)
                hashed_password = f"hashed_{user_create.password}"
                
                # Create the database model (simulated)
                db_user = UserDB(
                    id=1,  # In a real app, this would be generated by the database
                    email=user_create.email,
                    is_active=user_create.is_active,
                    hashed_password=hashed_password,
                    created_at=datetime.utcnow()
                )
                
                # Return as Pydantic model
                return UserInDB.model_validate(db_user)
            
            @staticmethod
            def update_user(user_id: int, user_update: UserUpdate) -> Optional[UserInDB]:
                """Update an existing user."""
                # Simulate fetching user from database
                db_user = UserDB(
                    id=user_id,
                    email="existing@example.com",
                    is_active=True,
                    hashed_password="hashed_password",
                    created_at=datetime.utcnow() - timedelta(days=1)
                )
                
                # Apply updates
                update_data = user_update.model_dump(exclude_unset=True)
                for key, value in update_data.items():
                    setattr(db_user, key, value)
                
                # Return as Pydantic model
                return UserInDB.model_validate(db_user)
        
        print("\nðŸ“ User Model Hierarchy for FastAPI & Database Integration")
        print("UserBase (Base class with common fields)")
        print("â”œâ”€â”€ UserCreate (API input for user creation)")
        print("â”‚   â””â”€â”€ + password field")
        print("â”œâ”€â”€ UserUpdate (API input for user updates)")
        print("â”‚   â”œâ”€â”€ Optional email")
        print("â”‚   â””â”€â”€ Optional is_active")
        print("â”œâ”€â”€ UserInDB (Internal model with hashed password)")
        print("â”‚   â”œâ”€â”€ + id field")
        print("â”‚   â”œâ”€â”€ + hashed_password field")
        print("â”‚   â””â”€â”€ + created_at field")
        print("â””â”€â”€ UserResponse (API output model)")
        print("    â”œâ”€â”€ + id field")
        print("    â””â”€â”€ + created_at field")
        
        print("\nðŸ” Demonstration: User creation flow")
        
        # Create a new user
        user_create = UserCreate(
            email="newuser@example.com",
            password="securepassword"
        )
        
        user_service = UserService()
        db_user = user_service.create_user(user_create)
        
        print("  âœ… User created in database:")
        print(f"  â€¢ ID: {db_user.id}")
        print(f"  â€¢ Email: {db_user.email}")
        print(f"  â€¢ Active: {db_user.is_active}")
        print(f"  â€¢ Hashed Password: {db_user.hashed_password}")
        print(f"  â€¢ Created At: {db_user.created_at}")
        
        # Convert to response model (using model_dump to exclude hashed_password)
        user_response = UserResponse.model_validate(db_user)
        print("\n  API Response (excludes sensitive fields):")
        print(f"  {user_response.model_dump_json()}")
        
        print("\nðŸ” Demonstration: User update flow")
        
        # Update an existing user
        user_update = UserUpdate(email="updated@example.com")
        updated_user = user_service.update_user(1, user_update)
        
        if updated_user:
            print("  âœ… User updated in database:")
            print(f"  â€¢ Email: {updated_user.email} (was: existing@example.com)")
            print(f"  â€¢ Other fields preserved")
            
            # Convert to response model
            response = UserResponse.model_validate(updated_user)
            print("\n  API Response:")
            print(f"  {response.model_dump_json()}")
        else:
            print("  âŒ User not found")
        
        print("\nðŸ” Demonstration: Mock FastAPI endpoint handlers")
        
        # Mock FastAPI handlers (pseudocode)
        print("\n  Example FastAPI endpoint handlers:")
        print("  ```python")
        print("  @app.post('/users', response_model=UserResponse)")
        print("  async def create_user(user: UserCreate):")
        print("      # FastAPI automatically validates against UserCreate")
        print("      db_user = user_service.create_user(user)")
        print("      # FastAPI automatically serializes using UserResponse")
        print("      return db_user")
        print("      ")
        print("  @app.put('/users/{user_id}', response_model=UserResponse)")
        print("  async def update_user(user_id: int, user: UserUpdate):")
        print("      # FastAPI automatically validates against UserUpdate")
        print("      db_user = user_service.update_user(user_id, user)")
        print("      if not db_user:")
        print("          raise HTTPException(404, 'User not found')")
        print("      # FastAPI automatically serializes using UserResponse")
        print("      return db_user")
        print("  ```")
        
        print("\nâ­ Best Practices for Integration:")
        print("  â€¢ Create different model types for different purposes")
        print("  â€¢ Use inheritance for common fields")
        print("  â€¢ Configure models with from_attributes=True for ORM integration")
        print("  â€¢ Keep sensitive data out of response models")
        print("  â€¢ Use the service layer pattern to separate business logic")
        print("  â€¢ Always validate input data at system boundaries")
        
        return {
            "base": UserBase,
            "create": UserCreate,
            "update": UserUpdate,
            "in_db": UserInDB,
            "response": UserResponse,
            "service": UserService
        }  # Return for use in later examples

    def run_demo(self):
        """
        Run a complete demonstration of Pydantic best practices.
        """
        print("\n" + "=" * 80)
        print("ðŸš€ RUNNING PYDANTIC BEST PRACTICES DEMO")
        print("=" * 80)
        
        # Run all demonstrations
        basic_model = self.demonstrate_basic_models()
        settings = self.demonstrate_config_management()
        nested_model = self.demonstrate_nested_models()
        versioned_models = self.demonstrate_model_evolution()
        error_handling = self.demonstrate_error_handling()
        integration = self.demonstrate_integration_patterns()
        
        print("\n" + "=" * 80)
        print("âœ… PYDANTIC BEST PRACTICES SUMMARY")
        print("=" * 80)
        
        print("\nðŸ”‘ Key Principles:")
        print("  1. Model Everything: Replace dictionaries with validated models")
        print("  2. Configuration via Settings: Centralize application configuration")
        print("  3. Immutability by Default: Prevent accidental state changes")
        print("  4. Validate Early: Reject invalid data at system boundaries")
        print("  5. Controlled Serialization: Use model_dump() and model_dump_json()")
        
        print("\nðŸ“š Common Patterns Demonstrated:")
        print("  â€¢ Basic model definition and validation")
        print("  â€¢ Environment-based configuration")
        print("  â€¢ Nested models and relationships")
        print("  â€¢ Model versioning for API evolution")
        print("  â€¢ Error handling and validation")
        print("  â€¢ Integration with other systems")
        
        print("\nðŸ› ï¸ Tools for Enforcement:")
        print("  â€¢ mypy with pydantic plugin for static type checking")
        print("  â€¢ ruff for linting and code quality")
        print("  â€¢ pytest with pydantic-factories for testing")
        print("  â€¢ Pre-commit hooks for validation before commits")
        
        print("\n" + "=" * 80)
        print("For more information, visit: https://docs.pydantic.dev/")
        print("=" * 80)


if __name__ == "__main__":
    # Run the demo
    demo = PydanticBestPractices()
    demo.run_demo()./environment.py
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
import os
import subprocess
import sys
from pathlib import Path
import shutil

# Try to import other modules
try:
    from observability import LoggingObservabilityStandards
except ImportError:
    # Mock class when running standalone
    class LoggingObservabilityStandards:
        def __init__(self):
            pass
        def create_basic_jsonl_logger(self):
            import logging
            return logging.getLogger("environment")


@dataclass
class BranchingStrategy:
    """Represents a Git branching strategy"""
    main_branch: str
    development_branch: str
    feature_prefix: str
    bugfix_prefix: str
    hotfix_prefix: str


@dataclass
class EnvFile:
    """Represents an environment file"""
    name: str
    purpose: str
    example_content: str


class EnvironmentManagement:
    """
    Environment Management & Setup
    
    A class representing best practices for Python project environment setup,
    repository management, and dependency handling.
    """
    
    def __init__(self):
        self.name = "Environment Management & Setup"
        self.recommended_python_version = "3.13 (as of mid-2025)"
        
        # Set up logging
        self.logging_module = LoggingObservabilityStandards()
        self.logger = self.logging_module.create_basic_jsonl_logger()
        
        # Git branching strategy
        self.branching_strategy = BranchingStrategy(
            main_branch="main",
            development_branch="dev",
            feature_prefix="feature/",
            bugfix_prefix="bugfix/",
            hotfix_prefix="hotfix/"
        )
        
        # Environment file patterns
        self.env_files = [
            EnvFile(
                ".env", 
                "Local development environment", 
                "DEBUG=True\nLOG_LEVEL=DEBUG\nDATABASE_URL=sqlite:///./dev.db"
            ),
            EnvFile(
                ".env.staging", 
                "Staging environment", 
                "DEBUG=False\nLOG_LEVEL=INFO\nDATABASE_URL=postgresql://user:pass@localhost/staging"
            ),
            EnvFile(
                ".env.prod", 
                "Production environment (loaded in CI/CD â†’ Secrets Manager at runtime)", 
                "DEBUG=False\nLOG_LEVEL=WARNING\nDATABASE_URL=postgresql://user:pass@prod-db/app"
            )
        ]
        
        # Dependency management tool
        self.dependency_tool = "uv"
        self.dependency_file = "pyproject.toml"
        self.lock_file = "uv.lock"
        
        # Essential commands for uv
        self.uv_commands = {
            "create_venv": "uv venv",
            "install_deps": "uv pip install -r uv.lock",
            "sync_deps": "uv pip sync",
            "compile_deps": "uv pip compile",
            "check_outdated": "uv pip list --outdated",
            "upgrade_deps": "uv pip upgrade",
            "security_audit": "uv pip audit"
        }
        
        self.logger.info("Environment management initialized", 
                        python_version=self.recommended_python_version,
                        dependency_tool=self.dependency_tool)
    
    def initialize_repository(self, name: str, description: str = "") -> str:
        """
        Initialize a new Git repository with recommended structure.
        Returns a string with the commands to run.
        """
        commands = [
            f"# Create repository directory",
            f"mkdir {name}",
            f"cd {name}",
            f"",
            f"# Initialize Git repository",
            f"git init",
            f"",
            f"# Create minimal README.md",
            f"echo '# {name}' > README.md",
            f"echo '' >> README.md",
            f"echo '{description}' >> README.md",
            f"",
            f"# Initial commit",
            f"git add README.md",
            f"git commit -m 'Initial commit'",
            f"",
            f"# Set up remote and push (assuming you've created a repo on GitHub)",
            f"git remote add origin git@github.com:yourusername/{name}.git",
            f"git push -u origin main",
            f"",
            f"# Create development branch",
            f"git checkout -b {self.branching_strategy.development_branch}",
            f"git push -u origin {self.branching_strategy.development_branch}"
        ]
        
        return "\n".join(commands)
    
    def create_environment_files(self, directory: Path = Path(".")) -> Dict[str, Path]:
        """
        Create the recommended environment files in the specified directory.
        Returns a dictionary mapping environment names to file paths.
        """
        created_files = {}
        
        for env_file in self.env_files:
            file_path = directory / env_file.name
            with open(file_path, 'w') as f:
                f.write(f"# {env_file.purpose}\n")
                f.write(env_file.example_content)
            
            created_files[env_file.name] = file_path
            
        # Create a .gitignore entry for .env to avoid committing secrets
        gitignore_path = directory / ".gitignore"
        gitignore_content = ""
        
        if gitignore_path.exists():
            with open(gitignore_path, 'r') as f:
                gitignore_content = f.read()
        
        if ".env" not in gitignore_content:
            with open(gitignore_path, 'a') as f:
                f.write("\n# Environment variables\n.env\n")
        
        return created_files
    
    def setup_pyproject_toml(self, project_name: str, version: str = "0.1.0") -> str:
        """
        Create a template pyproject.toml file with recommended structure.
        Returns the content of the file.
        """
        return f"""
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{project_name}"
version = "{version}"
description = "Add your project description here"
readme = "README.md"
requires-python = ">={self.recommended_python_version.split()[0]}"
license = {{ file = "LICENSE" }}
authors = [
    {{ name = "Your Name", email = "your.email@example.com" }}
]
dependencies = [
    # Add your project dependencies here
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.5",
    "mypy>=1.6.1",
]

[tool.ruff]
line-length = 100
target-version = "{self.recommended_python_version.split()[0]}"

[tool.mypy]
python_version = "{self.recommended_python_version.split()[0]}"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
"""
    
    def setup_venv_command(self, venv_name: Optional[str] = None) -> str:
        """
        Generate the command to create a virtual environment with uv.
        If venv_name is not provided, uses '.venv' as the default.
        """
        venv_path = venv_name or ".venv"
        return f"{self.uv_commands['create_venv']} {venv_path}"
    
    def generate_settings_loader(self) -> str:
        """
        Generate a Python code snippet for a settings loader that handles different environments.
        """
        return '''
from pathlib import Path
import os
from typing import Dict, Any
import tomli
import dotenv

class Settings:
    """Settings loader that handles multiple environments."""
    
    def __init__(self):
        self.environment = os.getenv("ENVIRONMENT", "local").lower()
        self._load_env_file()
        self._load_config()
        
    def _load_env_file(self) -> None:
        """Load the appropriate .env file based on environment."""
        if self.environment == "local":
            env_file = ".env"
        else:
            env_file = f".env.{self.environment}"
            
        # Load the environment file if it exists
        if Path(env_file).exists():
            dotenv.load_dotenv(env_file)
        else:
            print(f"Warning: Environment file {env_file} not found")
            
    def _load_config(self) -> None:
        """Load configuration from pyproject.toml or other sources."""
        # Load from pyproject.toml if available
        if Path("pyproject.toml").exists():
            with open("pyproject.toml", "rb") as f:
                config = tomli.load(f)
                # You can extract config values from the TOML file
                # self.some_config = config.get("tool", {}).get("my_app", {}).get("some_setting")
        
        # Set default values and override with environment variables
        self.debug = os.getenv("DEBUG", "False").lower() in ("true", "1", "yes")
        self.log_level = os.getenv("LOG_LEVEL", "INFO")
        self.database_url = os.getenv("DATABASE_URL", "")
        
    def __str__(self) -> str:
        """String representation of settings."""
        return f"Settings(environment={self.environment}, debug={self.debug}, log_level={self.log_level})"
        
# Usage:
# settings = Settings()
'''
    
    def get_dependency_management_commands(self) -> Dict[str, str]:
        """
        Return a dictionary of commonly used dependency management commands.
        """
        return {
            "Install dependencies from lock file": f"{self.uv_commands['install_deps']}",
            "Sync dependencies to match lock file exactly": f"{self.uv_commands['sync_deps']}",
            "Compile dependencies to lock file": f"{self.uv_commands['compile_deps']}",
            "Check for outdated packages": f"{self.uv_commands['check_outdated']}",
            "Upgrade packages": f"{self.uv_commands['upgrade_deps']}",
            "Run security audit": f"{self.uv_commands['security_audit']}",
        }
    
    def create_feature_branch_command(self, feature_name: str) -> str:
        """
        Generate a Git command to create a new feature branch.
        """
        branch_name = f"{self.branching_strategy.feature_prefix}{feature_name}"
        return f"git checkout {self.branching_strategy.development_branch} && git pull && git checkout -b {branch_name}"
    
    def create_bugfix_branch_command(self, bug_name: str) -> str:
        """
        Generate a Git command to create a new bugfix branch.
        """
        branch_name = f"{self.branching_strategy.bugfix_prefix}{bug_name}"
        return f"git checkout {self.branching_strategy.main_branch} && git pull && git checkout -b {branch_name}"
    
    def initialize_project(self, project_name: str, description: str = "") -> Dict[str, Any]:
        """
        Initialize a complete project with best practices.
        Returns information about created resources.
        
        This is a high-level method that combines multiple initialization steps.
        """
        self.logger.info(f"Initializing complete project", project_name=project_name)
        
        project_info = {
            "name": project_name,
            "description": description,
            "resources": {}
        }
        
        # Create project directory
        project_dir = Path(project_name)
        if not project_dir.exists():
            project_dir.mkdir(parents=True)
            self.logger.info("Created project directory", path=str(project_dir))
        
        # Create pyproject.toml
        pyproject_content = self.setup_pyproject_toml(project_name)
        pyproject_path = project_dir / "pyproject.toml"
        with open(pyproject_path, 'w') as f:
            f.write(pyproject_content)
        project_info["resources"]["pyproject_toml"] = str(pyproject_path)
        self.logger.info("Created pyproject.toml", path=str(pyproject_path))
        
        # Create environment files
        env_files = self.create_environment_files(project_dir)
        project_info["resources"]["env_files"] = {name: str(path) for name, path in env_files.items()}
        self.logger.info("Created environment files", files=list(env_files.keys()))
        
        # Create basic project structure
        src_dir = project_dir / "src" / project_name
        src_dir.mkdir(parents=True, exist_ok=True)
        (src_dir / "__init__.py").touch()
        
        tests_dir = project_dir / "tests"
        tests_dir.mkdir(exist_ok=True)
        (tests_dir / "__init__.py").touch()
        (tests_dir / f"test_{project_name}.py").touch()
        
        project_info["resources"]["structure"] = {
            "src": str(src_dir),
            "tests": str(tests_dir)
        }
        self.logger.info("Created basic project structure", src=str(src_dir), tests=str(tests_dir))
        
        # Create git repository
        git_init_result = subprocess.run(
            ["git", "-C", str(project_dir), "init"],
            capture_output=True,
            text=True
        )
        if git_init_result.returncode == 0:
            # Create .gitignore
            gitignore_path = project_dir / ".gitignore"
            with open(gitignore_path, 'w') as f:
                f.write(self._get_default_gitignore())
            
            # Create README.md
            readme_path = project_dir / "README.md"
            with open(readme_path, 'w') as f:
                f.write(f"# {project_name}\n\n{description}")
            
            project_info["resources"]["git"] = {
                "initialized": True,
                "gitignore": str(gitignore_path),
                "readme": str(readme_path)
            }
            self.logger.info("Initialized Git repository", gitignore=str(gitignore_path))
        else:
            project_info["resources"]["git"] = {"initialized": False}
            self.logger.warning("Failed to initialize Git repository", 
                              error=git_init_result.stderr)
        
        return project_info
    
    def _get_default_gitignore(self) -> str:
        """Return default .gitignore content for Python projects"""
        return """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/
.venv/
.env

# Testing
.coverage
htmlcov/

# Logs
*.log

# Environment files
.env
.env.*
!.env.example

# IDE
.idea/
.vscode/
*.swp
*.swo
"""
    
    def __str__(self) -> str:
        """Return a string representation of the environment manager"""
        return f"Environment Management (Python {self.recommended_python_version}, {self.dependency_tool})"


# Example usage
if __name__ == "__main__":
    env_management = EnvironmentManagement()
    
    print(f"ðŸ”§ {env_management}")
    
    print("\nðŸŒ± Recommended Python Version:")
    print(f"- Python {env_management.recommended_python_version}")
    
    print("\nðŸŒ¿ Git Branching Strategy:")
    print(f"- Main branch: {env_management.branching_strategy.main_branch}")
    print(f"- Development branch: {env_management.branching_strategy.development_branch}")
    print(f"- Feature branches: {env_management.branching_strategy.feature_prefix}*")
    print(f"- Bugfix branches: {env_management.branching_strategy.bugfix_prefix}*")
    print(f"- Hotfix branches: {env_management.branching_strategy.hotfix_prefix}*")
    
    print("\nðŸ“ Environment Files:")
    for env_file in env_management.env_files:
        print(f"- {env_file.name}: {env_file.purpose}")
    
    print("\nðŸ“¦ Dependency Management:")
    print(f"- Tool: {env_management.dependency_tool}")
    print(f"- Dependency file: {env_management.dependency_file}")
    print(f"- Lock file: {env_management.lock_file}")
    
    print("\nâš™ï¸ Common Commands:")
    for description, command in env_management.get_dependency_management_commands().items():
        print(f"- {description}: `{command}`")
    
    print("\nðŸš€ Quick Start:")
    repo_name = "example-project"
    print(f"To initialize a new project '{repo_name}':")
    print("```bash")
    print(env_management.initialize_repository(repo_name, "An example project"))
    print("```")
    
    print("\nTo create a virtual environment:")
    print(f"`{env_management.setup_venv_command()}`")
    
    print("\nTo create a feature branch:")
    print(f"`{env_management.create_feature_branch_command('user-authentication')}`")./dry.py
class DRY:
    """
    Don't Repeat Yourself (DRY) Principle
    
    A simple class representing the DRY software development principle.
    """
    
    def __init__(self):
        self.name = "DRY"
        self.full_name = "Don't Repeat Yourself"
        self.core_idea = "Every piece of knowledge must have a single, unambiguous representation within the codebase."
        
        # Guidelines for implementing DRY
        self.practical_enforcement = [
            "Centralize shared logic in functions or classes",
            "Extract common constants/config values",
            "Use parametrized tests to avoid duplicate test logic",
            "Document conventions in docs/ to prevent ad-hoc re-implementation"
        ]
        
        # Benefits of following DRY
        self.benefits = [
            "Reduced code maintenance overhead",
            "Fewer bugs due to inconsistent updates",
            "Easier refactoring and code evolution",
            "Better reusability of components"
        ]
    
    def get_examples(self):
        """Return examples of non-DRY and DRY code"""
        examples = {
            "non_dry": """
# Non-DRY code with duplication
def process_users():
    # Database connection repeated in multiple functions
    conn = connect_to_database("localhost", "mydb", "user", "pass")
    # Process users...
    conn.close()

def process_orders():
    # Same database connection logic repeated
    conn = connect_to_database("localhost", "mydb", "user", "pass")
    # Process orders...
    conn.close()
""",
            "dry": """
# DRY code with centralized logic
def get_database_connection():
    return connect_to_database("localhost", "mydb", "user", "pass")

def process_users():
    conn = get_database_connection()
    # Process users...
    conn.close()

def process_orders():
    conn = get_database_connection()
    # Process orders...
    conn.close()
"""
        }
        return examples
    
    def __str__(self):
        """String representation of the DRY principle"""
        return f"{self.full_name} ({self.name}): {self.core_idea}"


# Example usage
if __name__ == "__main__":
    dry = DRY()
    
    print(f"ðŸ’¡ Principle: {dry}")
    print("\nðŸ‘‰ Practical Enforcement:")
    for guideline in dry.practical_enforcement:
        print(f"- {guideline}")
    
    print("\nâœ¨ Benefits:")
    for benefit in dry.benefits:
        print(f"- {benefit}")
    
    print("\nðŸ’» Code Examples:")
    examples = dry.get_examples()
    print("âŒ Non-DRY Code:")
    print(examples["non_dry"])
    print("âœ… DRY Code:")
    print(examples["dry"])./sample_app.py
#!/usr/bin/env python3
"""
Sample Application Demonstrating Integrated Best Practices

This module shows how to use the different best practice modules together
in a real application. It demonstrates:

1. Project initialization following best practices
2. Modern Python syntax and validation
3. An API with proper logging and error handling
4. Background tasks integration

This is a concrete example of the principles taught in this repository.
"""

import os
import sys
import asyncio
from pathlib import Path
from typing import List, Dict, Optional, Any
from contextlib import asynccontextmanager

# Import our best practice modules
from dry import DRY
from environment import EnvironmentManagement
from observability import LoggingObservabilityStandards
from validation import DataValidationAndConfiguration, ModelType, PydanticModel
from tasks import BackgroundTasksAndConcurrency
from fast_api_best_practice import FastAPIBestPractices

# Import other required libraries
from fastapi import FastAPI, Depends, BackgroundTasks, HTTPException
from pydantic import BaseModel, Field, EmailStr


class SampleApp:
    """
    Demonstrates integration of best practice modules in a real application.
    
    This class implements a sample todo app that uses:
    - Pydantic for data validation (validation.py)
    - Structured logging (logging.py)
    - Background tasks (tasks.py)
    - FastAPI best practices (fast_api_best_practice.py)
    """
    
    def __init__(self):
        """
        Initialize the sample application with integrated best practices.
        """
        # Initialize logging first (foundation for all other components)
        self.logger_module = LoggingObservabilityStandards()
        self.logger = self.logger_module.create_basic_jsonl_logger()
        self.logger.info("Initializing sample application")
        
        # Initialize environment management
        self.env_manager = EnvironmentManagement() 
        
        # Initialize data validation module
        self.validation = DataValidationAndConfiguration()
        
        # Initialize background tasks module
        self.tasks = BackgroundTasksAndConcurrency()
        
        # Define Pydantic models for our application
        self.define_models()
        
        # Setup API with lifespan to handle startup/shutdown
        @asynccontextmanager
        async def lifespan(app: FastAPI):
            # Startup actions
            self.logger.info("Application startup")
            
            # For demonstration purposes, we'll initialize some todo items
            self.todos = [
                {"id": 1, "title": "Learn Python Best Practices", "completed": True},
                {"id": 2, "title": "Build a FastAPI application", "completed": False},
                {"id": 3, "title": "Implement background tasks", "completed": False}
            ]
            
            yield
            
            # Shutdown actions
            self.logger.info("Application shutdown")
        
        # Create the FastAPI app
        self.app = FastAPI(
            title="Sample Todo App",
            description="Sample application demonstrating integrated best practices",
            version="1.0.0",
            lifespan=lifespan
        )
        
        # Set up routes
        self.setup_routes()
        
        self.logger.info("Sample application initialized successfully")
    
    def define_models(self):
        """Define Pydantic models for the application using our validation best practices."""
        # We'll create these inline, but the validation module helps us identify patterns
        class TodoBase(BaseModel):
            """Base todo model with shared attributes"""
            title: str = Field(..., min_length=1, max_length=100, description="Title of the todo item")
            completed: bool = Field(default=False, description="Whether the item is completed")
        
        class TodoCreate(TodoBase):
            """Model for creating a new todo item"""
            pass
        
        class Todo(TodoBase):
            """Model for todo responses including the ID"""
            id: int = Field(..., gt=0, description="Unique identifier for the todo item")
            
            class Config:
                from_attributes = True
        
        # Store models for use in routes
        self.TodoBase = TodoBase
        self.TodoCreate = TodoCreate
        self.Todo = Todo
    
    def setup_routes(self):
        """Set up the API routes following best practices."""
        
        @self.app.get("/todos", response_model=List[self.Todo], tags=["todos"])
        async def get_todos():
            """Get all todo items."""
            self.logger.info("Retrieving all todos", count=len(self.todos))
            return self.todos
        
        @self.app.get("/todos/{todo_id}", response_model=self.Todo, tags=["todos"])
        async def get_todo(todo_id: int):
            """Get a specific todo item by ID."""
            todo = next((t for t in self.todos if t["id"] == todo_id), None)
            if not todo:
                self.logger.warning("Todo not found", todo_id=todo_id)
                raise HTTPException(status_code=404, detail="Todo not found")
            
            self.logger.info("Retrieved todo", todo_id=todo_id)
            return todo
        
        @self.app.post("/todos", response_model=self.Todo, status_code=201, tags=["todos"])
        async def create_todo(todo: self.TodoCreate, background_tasks: BackgroundTasks):
            """Create a new todo item."""
            # Generate ID (in a real app, this would be handled by the database)
            new_id = max(t["id"] for t in self.todos) + 1 if self.todos else 1
            
            # Create the new todo
            new_todo = {
                "id": new_id,
                **todo.model_dump()
            }
            
            # Add to our list
            self.todos.append(new_todo)
            
            # Log using structured logging
            self.logger.info("Todo created", todo_id=new_id, title=todo.title)
            
            # Add a background task to demonstrate task integration
            background_tasks.add_task(self.process_new_todo, new_todo)
            
            return new_todo
        
        @self.app.put("/todos/{todo_id}", response_model=self.Todo, tags=["todos"])
        async def update_todo(todo_id: int, todo: self.TodoCreate):
            """Update an existing todo item."""
            # Find the todo
            index = next((i for i, t in enumerate(self.todos) if t["id"] == todo_id), None)
            if index is None:
                self.logger.warning("Todo not found for update", todo_id=todo_id)
                raise HTTPException(status_code=404, detail="Todo not found")
            
            # Update the todo
            updated_todo = {
                "id": todo_id,
                **todo.model_dump()
            }
            self.todos[index] = updated_todo
            
            self.logger.info("Todo updated", todo_id=todo_id, title=todo.title)
            return updated_todo
        
        @self.app.delete("/todos/{todo_id}", status_code=204, tags=["todos"])
        async def delete_todo(todo_id: int):
            """Delete a todo item."""
            # Find the todo
            index = next((i for i, t in enumerate(self.todos) if t["id"] == todo_id), None)
            if index is None:
                self.logger.warning("Todo not found for deletion", todo_id=todo_id)
                raise HTTPException(status_code=404, detail="Todo not found")
            
            # Remove the todo
            self.todos.pop(index)
            
            self.logger.info("Todo deleted", todo_id=todo_id)
    
    async def process_new_todo(self, todo: Dict[str, Any]):
        """
        Process a new todo item in the background.
        
        This demonstrates a background task that would typically do something like:
        - Send notifications
        - Update search indices
        - Generate reports
        """
        await asyncio.sleep(2)  # Simulate some processing time
        self.logger.info("Background processing of todo complete", todo_id=todo["id"])
    
    def run(self, host: str = "127.0.0.1", port: int = 8000):
        """Run the sample application."""
        import uvicorn
        self.logger.info("Starting sample application", host=host, port=port)
        uvicorn.run(self.app, host=host, port=port)


if __name__ == "__main__":
    app = SampleApp()
    app.run() ./observability.py
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable
import json
import os
import sys
import logging
import datetime
import uuid
import traceback
from contextlib import contextmanager
import contextvars

@dataclass
class LogField:
    """Represents a standard log record field"""
    name: str
    example: str
    description: str
    required: bool = False


@dataclass
class LoggingLibrary:
    """Represents a recommended logging library"""
    name: str
    url: str
    purpose: str
    install_command: str
    is_preferred: bool = False


class LoggingObservabilityStandards:
    """
    Logging & Observability Standards
    
    A class representing the standard logging and observability practices
    for Python applications.
    """
    
    def __init__(self):
        self.name = "Logging & Observability Standards"
        self.format = "JSON Lines (jsonl)"
        self.format_description = "All runtime logs must be emitted as structured JSON objects, with one complete JSON object per line."
        
        # Standard Log Record Fields
        self.standard_fields = [
            LogField("timestamp", "2025-05-12T13:37:49.123Z", "ISO-8601 format, always in UTC.", True),
            LogField("level", "INFO / ERROR / DEBUG", "Standard Python logging levels.", True),
            LogField("message", "User created successfully", "Concise, human-readable description of the event.", True),
            LogField("logger", "app.services.users", "Name of the logger instance (often corresponds to module)."),
            LogField("module", "users", "Python module name where the log originated."),
            LogField("function", "create_user", "Function or method name."),
            LogField("line", "42", "Source code line number."),
            LogField("trace_id", "uuid-03f4...", "Correlation ID for tracking requests across services/calls."),
            LogField("exc_info", "Traceback... or null", "Exception traceback string, if an exception occurred."),
            LogField("context", '{"user_id": 123, ...}', "Optional dictionary for domain-specific context."),
        ]
        
        # Recommended logging libraries
        self.recommended_libraries = [
            LoggingLibrary(
                "structlog", 
                "https://www.structlog.org/", 
                "Powerful wrapper around standard logging, enabling flexible processor pipelines for structured output (JSON, key-value).",
                "uv pip install structlog",
                True
            ),
            LoggingLibrary(
                "python-json-logger",
                "https://github.com/madzak/python-json-logger",
                "Drop-in logging.Formatter subclass that produces JSON output. Simpler alternative if structlog feels too complex.",
                "uv pip install python-json-logger"
            ),
            LoggingLibrary(
                "loguru",
                "https://loguru.readthedocs.io/",
                "Batteries-included logging library offering a different API, with built-in support for JSON sinks and file rotation.",
                "uv pip install loguru"
            )
        ]
        
        # Best practices
        self.best_practices = [
            "Log to stdout/stderr: In containerized environments, always log to standard output/error streams.",
            "Never Log Sensitive Data: Avoid logging secrets, passwords, API keys, PII, or sensitive financial data.",
            "Use Correlation IDs: Propagate a unique request or trace ID through all log messages related to that request/task.",
            "Configurable Log Level: Make the logging level configurable via an environment variable (e.g., LOG_LEVEL).",
            "Development Logging: For local development, consider logging to a file with rotation.",
            "Alerting & Monitoring Hooks: Integrate critical error logging with alerting systems.",
            "Test Log Output: Include tests to assert that specific log messages are emitted correctly."
        ]
        
        # Log level guidelines
        self.log_levels = {
            "DEBUG": "Detailed information for troubleshooting (function entry/exit points, variable values)",
            "INFO": "Normal operations (request handled, service actions)",
            "WARNING": "Potential issues (deprecated API calls, service degradation)",
            "ERROR": "Error conditions (failed to process request, database errors)",
            "CRITICAL": "Critical failures (service unavailable, data corruption)"
        }
        
        # Context variables for request tracking
        self.request_id_var = contextvars.ContextVar("request_id", default=None)
        self.trace_id_var = contextvars.ContextVar("trace_id", default=None)
        self.user_id_var = contextvars.ContextVar("user_id", default=None)
    
    def get_structlog_implementation(self) -> str:
        """Returns the recommended structlog implementation code"""
        return """
# src/<app_name>/logging_config.py
import logging
import sys
import structlog
import os # For environment variables

def setup_logging():
    \"\"\"Configures logging using structlog to output JSON lines.\"\"\"

    log_level_name = os.getenv("LOG_LEVEL", "INFO").upper()
    log_level = getattr(logging, log_level_name, logging.INFO)

    # Configure standard logging first
    logging.basicConfig(
        format="%(message)s", # Basic format, structlog processors will handle the details
        stream=sys.stdout,    # Log to stdout for containerized environments
        level=log_level,
    )

    # Configure structlog
    structlog.configure(
        processors=[
            # Add log level and logger name info from the standard logger
            structlog.stdlib.add_log_level,
            structlog.stdlib.add_logger_name,
            # Add contextual information (bound variables)
            structlog.contextvars.merge_contextvars,
            # Add caller info (module, function, line number)
            structlog.processors.CallsiteParameterAdder(
                parameters=[
                    structlog.processors.CallsiteParameter.MODULE,
                    structlog.processors.CallsiteParameter.FUNC_NAME,
                    structlog.processors.CallsiteParameter.LINENO,
                ]
            ),
            # Add timestamp in ISO format (UTC)
            structlog.processors.TimeStamper(fmt="iso", utc=True),
            # Render exceptions
            structlog.processors.StackInfoRenderer(), # Adds stack info for exceptions
            structlog.processors.format_exc_info,     # Formats exception info
            # Render the final log record as JSON
            structlog.processors.JSONRenderer(),
        ],
        # Use a standard logger wrapper for compatibility
        wrapper_class=structlog.stdlib.BoundLogger,
        # Use logger factory that integrates with standard logging
        logger_factory=structlog.stdlib.LoggerFactory(),
        # Cache logger instances for performance
        cache_logger_on_first_use=True,
    )

# Call this function early in your application startup
# setup_logging()

# Get a logger instance
# logger = structlog.get_logger("my_module")

# Example Usage:
# logger.info("User logged in", user_id=456, ip_address="192.168.1.100")
# try:
#     1 / 0
# except ZeroDivisionError:
#     logger.error("Division failed", exc_info=True)
"""
    
    def get_stdlib_implementation(self) -> str:
        """Returns the standard library implementation code"""
        return """
import logging
import json
import sys
import traceback
import datetime
from typing import Dict, Any, Optional, Union
from contextlib import contextmanager
import uuid
import os

# Thread-local storage for request context
import contextvars
request_id_var = contextvars.ContextVar("request_id", default=None)
trace_id_var = contextvars.ContextVar("trace_id", default=None)
user_id_var = contextvars.ContextVar("user_id", default=None)


class JsonlFormatter(logging.Formatter):
    \"\"\"JSON Lines formatter for structured logging\"\"\"
    
    def format(self, record: logging.LogRecord) -> str:
        \"\"\"Format LogRecord as JSON string\"\"\"
        log_object = {
            # Standard fields (always included)
            "timestamp": datetime.datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "message": record.getMessage(),
            
            # Source location fields
            "logger": record.name,
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
            
            # Context fields
            "trace_id": getattr(record, "trace_id", None) or trace_id_var.get(),
            "request_id": getattr(record, "request_id", None) or request_id_var.get(),
            "user_id": getattr(record, "user_id", None) or user_id_var.get(),
        }
        
        # Include exception info if present
        if record.exc_info:
            log_object["exc_info"] = self.formatException(record.exc_info)
        
        # Include any extra attributes from the LogRecord
        for key, value in record.__dict__.items():
            if key not in ["args", "asctime", "created", "exc_info", "exc_text", "filename",
                          "funcName", "id", "levelname", "levelno", "lineno", "module",
                          "msecs", "message", "msg", "name", "pathname", "process",
                          "processName", "relativeCreated", "stack_info", "thread", "threadName",
                          "trace_id", "request_id", "user_id"]:
                log_object[key] = value
        
        return json.dumps(log_object)


def setup_logging(log_level: str = "INFO") -> logging.Logger:
    \"\"\"Set up a logger with JSON Lines formatting\"\"\"
    # Get the log level from the string name
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    
    # Configure the root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(numeric_level)
    
    # Create a handler that writes to stdout
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(JsonlFormatter())
    root_logger.addHandler(handler)
    
    return root_logger


@contextmanager
def log_context(**context):
    \"\"\"Context manager for adding context to logs\"\"\"
    # Store the previous context values
    prev_trace_id = trace_id_var.get()
    prev_request_id = request_id_var.get()
    prev_user_id = user_id_var.get()
    
    # Set the new context values
    if "trace_id" in context:
        trace_id_var.set(context["trace_id"])
    if "request_id" in context:
        request_id_var.set(context["request_id"])
    if "user_id" in context:
        user_id_var.set(context["user_id"])
    
    try:
        yield
    finally:
        # Restore the previous context values
        trace_id_var.set(prev_trace_id)
        request_id_var.set(prev_request_id)
        user_id_var.set(prev_user_id)


# Example usage:
# logger = setup_logging("DEBUG")
# with log_context(request_id="req-123", user_id=456):
#     logger.info("Processing request")
#     try:
#         # Some operation
#         result = 1 / 0
#     except Exception as e:
#         logger.error("Operation failed", exc_info=True, operation="division")
"""
    
    def get_fastapi_integration(self) -> str:
        """Returns FastAPI integration code"""
        return """
import uuid
import time
from fastapi import FastAPI, Request, Response
from fastapi.middleware.base import BaseHTTPMiddleware
import structlog
import logging
import os

# Configure logging
logging.basicConfig(
    level=getattr(logging, os.getenv("LOG_LEVEL", "INFO").upper()),
    format="%(message)s",
)

# Configure structlog
structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.contextvars.merge_contextvars,
        structlog.processors.TimeStamper(fmt="iso", utc=True),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger("api")

# Create a context var for storing trace ID
request_id_var = contextvars.ContextVar("request_id", default=None)
user_id_var = contextvars.ContextVar("user_id", default=None)


class LoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # Generate a unique ID for this request
        request_id = str(uuid.uuid4())
        request_id_var.set(request_id)
        
        # Add the request ID to request state for handlers to access
        request.state.request_id = request_id
        
        # Log the start of the request
        logger.info(
            "Request started", 
            method=request.method, 
            path=request.url.path,
            request_id=request_id,
            client=request.client.host if request.client else None
        )
        
        # Time the request
        start_time = time.time()
        
        try:
            # Process the request
            response = await call_next(request)
            
            # Calculate processing time
            process_time = time.time() - start_time
            
            # Add request ID to response headers
            response.headers["X-Request-ID"] = request_id
            
            # Log the completed request
            logger.info(
                "Request completed",
                request_id=request_id,
                status_code=response.status_code,
                process_time=f"{process_time:.4f}s",
            )
            
            return response
            
        except Exception as e:
            # Calculate processing time
            process_time = time.time() - start_time
            
            # Log the exception
            logger.error(
                "Request failed",
                request_id=request_id,
                error=str(e),
                exc_info=True,
                process_time=f"{process_time:.4f}s",
            )
            raise


# Example usage:
# app = FastAPI()
# app.add_middleware(LoggingMiddleware)
# 
# @app.get("/")
# async def root():
#     logger.info("Inside root endpoint", custom_field="value")
#     return {"message": "Hello World"}
"""
    
    def get_sentry_integration(self) -> str:
        """Returns code for Sentry integration"""
        return """
import sentry_sdk
from sentry_sdk.integrations.logging import LoggingIntegration
import logging

# Configure standard logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configure Sentry for error tracking
sentry_sdk.init(
    dsn="https://your-sentry-dsn@sentry.io/12345",  # Replace with your actual DSN
    # Set traces_sample_rate to 1.0 to capture 100% of transactions for performance monitoring
    # We recommend adjusting this value in production
    traces_sample_rate=0.2,  # Capture 20% of transactions
    
    # Configure Sentry to capture logs
    integrations=[
        LoggingIntegration(
            level=logging.INFO,      # Capture info and above as breadcrumbs
            event_level=logging.ERROR  # Send errors as events
        ),
    ],
    
    # Include environment info
    environment=os.getenv("ENVIRONMENT", "development"),
    
    # Associate users with errors by setting the user context
    # sentry_sdk.set_user({"id": user_id, "email": user_email})
)

# Example usage:
# try:
#     division_by_zero = 1 / 0
# except Exception as e:
#     logger.error("Error performing calculation", exc_info=True)
#     # Error will be captured by Sentry
"""
    
    def create_basic_jsonl_logger(self) -> logging.Logger:
        """Create and return a basic JSONL-formatted logger"""
        # Configure a logger using Python's built-in logging module
        class JsonlFormatter(logging.Formatter):
            def format(self, record):
                log_record = {
                    "timestamp": datetime.datetime.utcnow().isoformat() + "Z",
                    "level": record.levelname,
                    "message": record.getMessage(),
                    "logger": record.name,
                    "module": record.module,
                    "function": record.funcName,
                    "line": record.lineno,
                }
                
                # Add extra fields if available
                for key, value in record.__dict__.items():
                    if key not in ["args", "asctime", "created", "exc_info", "exc_text", "filename",
                                "funcName", "id", "levelname", "levelno", "lineno", "module",
                                "msecs", "message", "msg", "name", "pathname", "process",
                                "processName", "relativeCreated", "stack_info", "thread", "threadName"]:
                        log_record[key] = value
                
                # Add exception info if present
                if record.exc_info:
                    log_record["exc_info"] = self.formatException(record.exc_info)
                
                return json.dumps(log_record)
        
        # Create logger
        logger = logging.getLogger("app")
        logger.setLevel(logging.INFO)
        
        # Create handler
        handler = logging.StreamHandler(sys.stdout)
        handler.setFormatter(JsonlFormatter())
        
        # Only add the handler if it's not already there
        if not logger.handlers:
            logger.addHandler(handler)
        
        return logger
    
    def __str__(self):
        """String representation of logging standards"""
        return f"{self.name} with {self.format} format"


# Example usage
if __name__ == "__main__":
    logging_standards = LoggingObservabilityStandards()
    
    print(f"ðŸ” {logging_standards}")
    
    print("\nðŸ“‹ Standard Log Record Fields:")
    for field in logging_standards.standard_fields:
        req_mark = "*" if field.required else " "
        print(f"{req_mark} {field.name}: {field.example}")
        print(f"  {field.description}")
    
    print("\nðŸ“š Recommended Libraries:")
    for lib in logging_standards.recommended_libraries:
        star = "â­" if lib.is_preferred else " "
        print(f"{star} {lib.name}: {lib.purpose}")
        print(f"  {lib.url}")
        print(f"  Install: {lib.install_command}")
    
    print("\nâœ… Best Practices:")
    for practice in logging_standards.best_practices:
        print(f"â€¢ {practice}")
    
    print("\nðŸ”§ Log Level Guidelines:")
    for level, description in logging_standards.log_levels.items():
        print(f"â€¢ {level}: {description}")
    
    print("\nðŸ’» Example Implementation (structlog):")
    print(logging_standards.get_structlog_implementation()) ./solid.py
class SOLID:
    """
    SOLID Principles of Object-Oriented Design
    
    A simple class representing the five SOLID design principles.
    """
    
    def __init__(self):
        self.name = "SOLID"
        self.core_idea = "Five principles that promote maintainable, extensible OOP designs."
        
        # The five SOLID principles
        self.principles = {
            "S": {
                "name": "Single-Responsibility",
                "description": "Each module/class handles one concern.",
                "example": """
# Bad: Class with multiple responsibilities
class User:
    def __init__(self, name):
        self.name = name
    
    def save_to_database(self):
        # Database logic here
        print(f"Saving {self.name} to database")
    
    def generate_report(self):
        # Report generation logic here
        print(f"Generating report for {self.name}")
""",
                "improved": """
# Good: Separate classes for different responsibilities
class User:
    def __init__(self, name):
        self.name = name

class UserRepository:
    def save(self, user):
        # Database logic here
        print(f"Saving {user.name} to database")

class ReportGenerator:
    def generate_for_user(self, user):
        # Report generation logic here
        print(f"Generating report for {user.name}")
"""
            },
            "O": {
                "name": "Open-Closed",
                "description": "Classes are open for extension, closed for modification.",
                "example": """
# Bad: Requires modification to add new shapes
class AreaCalculator:
    def calculate_area(self, shape):
        if isinstance(shape, Rectangle):
            return shape.width * shape.height
        elif isinstance(shape, Circle):
            return 3.14 * shape.radius ** 2
        # Need to modify this class for each new shape
""",
                "improved": """
# Good: Open for extension through polymorphism
class Shape:
    def area(self):
        pass

class Rectangle(Shape):
    def __init__(self, width, height):
        self.width = width
        self.height = height
    
    def area(self):
        return self.width * self.height

class Circle(Shape):
    def __init__(self, radius):
        self.radius = radius
    
    def area(self):
        return 3.14 * self.radius ** 2

class AreaCalculator:
    def calculate_area(self, shape):
        return shape.area()  # Polymorphic call
"""
            },
            "L": {
                "name": "Liskov Substitution",
                "description": "Subclasses should be drop-in replacements for their base types.",
                "example": """
# Bad: Square violates Rectangle's behavior
class Rectangle:
    def __init__(self, width, height):
        self.width = width
        self.height = height
    
    def set_width(self, width):
        self.width = width
    
    def set_height(self, height):
        self.height = height

class Square(Rectangle):
    def __init__(self, side):
        super().__init__(side, side)
    
    def set_width(self, width):
        self.width = width
        self.height = width  # Changing behavior!
    
    def set_height(self, height):
        self.height = height
        self.width = height  # Changing behavior!
""",
                "improved": """
# Good: Shape hierarchy respects Liskov principle
class Shape:
    def area(self):
        pass

class Rectangle(Shape):
    def __init__(self, width, height):
        self.width = width
        self.height = height
    
    def area(self):
        return self.width * self.height

class Square(Shape):  # Not a Rectangle subclass
    def __init__(self, side):
        self.side = side
    
    def area(self):
        return self.side * self.side
"""
            },
            "I": {
                "name": "Interface Segregation",
                "description": "Prefer small, focused interfaces over monolithic ones.",
                "example": """
# Bad: Monolithic interface forces implementations of unneeded methods
class Worker:
    def work(self):
        pass
    
    def eat(self):
        pass
    
    def sleep(self):
        pass

class Robot(Worker):
    def work(self):
        print("Robot working")
    
    def eat(self):
        raise NotImplementedError("Robots don't eat")  # Forced to implement
    
    def sleep(self):
        raise NotImplementedError("Robots don't sleep")  # Forced to implement
""",
                "improved": """
# Good: Segregated interfaces
class Workable:
    def work(self):
        pass

class Eatable:
    def eat(self):
        pass

class Sleepable:
    def sleep(self):
        pass

class Human(Workable, Eatable, Sleepable):
    def work(self):
        print("Human working")
    
    def eat(self):
        print("Human eating")
    
    def sleep(self):
        print("Human sleeping")

class Robot(Workable):  # Only implements what it needs
    def work(self):
        print("Robot working")
"""
            },
            "D": {
                "name": "Dependency Inversion",
                "description": "Depend on abstractions, not concrete implementations.",
                "example": """
# Bad: High-level module depends on low-level module
class MySQLDatabase:
    def save(self, data):
        print(f"Saving {data} to MySQL")

class UserService:
    def __init__(self):
        self.database = MySQLDatabase()  # Direct dependency
    
    def save_user(self, user):
        self.database.save(user)
""",
                "improved": """
# Good: Dependency injected through abstraction
class Database:  # Abstract interface
    def save(self, data):
        pass

class MySQLDatabase(Database):
    def save(self, data):
        print(f"Saving {data} to MySQL")

class PostgreSQLDatabase(Database):
    def save(self, data):
        print(f"Saving {data} to PostgreSQL")

class UserService:
    def __init__(self, database):  # Dependency injection
        self.database = database
    
    def save_user(self, user):
        self.database.save(user)

# Usage
db = MySQLDatabase()  # Or PostgreSQLDatabase()
service = UserService(db)
"""
            }
        }
    
    def get_principle(self, letter):
        """Get details for a specific SOLID principle by its letter"""
        if letter.upper() in self.principles:
            return self.principles[letter.upper()]
        return None
    
    def __str__(self):
        """String representation of SOLID principles"""
        return f"SOLID Principles: {self.core_idea}"


# Example usage
if __name__ == "__main__":
    solid = SOLID()
    
    print(f"ðŸ—ï¸ {solid}")
    print("\nðŸ§± The Five SOLID Principles:")
    
    for letter, principle in solid.principles.items():
        print(f"\nðŸ”¹ {letter}: {principle['name']}")
        print(f"   {principle['description']}")
        
        # Print an example for one principle to demonstrate
        if letter == 'S':  # Single Responsibility example
            print("\nðŸ“‹ Example:")
            print("âŒ Violating Single Responsibility:")
            print(principle['example'])
            print("âœ… Following Single Responsibility:")
            print(principle['improved'])
    
    # Ask for user input to explore more principles
    print("\nðŸ’¡ Run this program and enter a letter (S, O, L, I, D) to see examples for that principle.")
    print("   For example, type 'O' to see Open-Closed principle examples.")
    
    """
    # Uncomment this code to make the script interactive
    letter = input("\nEnter a SOLID principle letter to see examples: ").upper()
    principle = solid.get_principle(letter)
    if principle:
        print(f"\nðŸ”¹ {letter}: {principle['name']}")
        print(f"   {principle['description']}")
        print("\nðŸ“‹ Example:")
        print(f"âŒ Violating {principle['name']}:")
        print(principle['example'])
        print(f"âœ… Following {principle['name']}:")
        print(principle['improved'])
    else:
        print(f"Principle '{letter}' not found. Please enter S, O, L, I, or D.")
    """./modern.py
class ModernPythonSyntax:
    """
    Modern Python Syntax & Idioms
    
    A class representing modern Python syntax features and idioms
    that should be used in Python 3.12+ codebases.
    """
    
    def __init__(self):
        self.name = "Modern Python Syntax & Idioms"
        self.min_python_version = "3.12+"
        self.preferred_version = "3.13"
        
        # Organize features by category
        self.string_formatting = {
            "name": "F-strings",
            "description": "Use f-strings for string formatting",
            "example": 'name = "World"\ngreeting = f"Hello, {name}!"',
            "pep": None
        }
        
        self.type_system = {
            "type_hints": {
                "name": "Type Hints",
                "description": "Improves clarity; run tools like mypy for static checks",
                "example": "def greet(name: str) -> str:\n    return f'Hello, {name}!'",
                "pep": "484"
            },
            "data_classes": {
                "name": "Data Classes",
                "description": "Reduce boilerplate for data containers via @dataclass",
                "example": """
@dataclass
class User:
    name: str
    email: str
    age: int = 0
""",
                "pep": "557"
            },
            "type_parameter_syntax": {
                "name": "New Type Parameter Syntax",
                "description": "For Python 3.12+, use the new syntax for defining generic functions and classes",
                "example": """
def first[T](items: list[T]) -> T:
    return items[0]
    
class Box[T]:
    def __init__(self, value: T):
        self.value = T
        
type IntOrStr = int | str
""",
                "pep": "695"
            }
        }
        
        self.file_system = {
            "name": "Pathlib",
            "description": "For filesystem paths; prefer os.scandir() over os.listdir() when metadata is needed",
            "example": """
from pathlib import Path

# Create paths
config_path = Path("config/settings.toml")
parent_dir = config_path.parent

# Check properties
if config_path.exists() and config_path.is_file():
    content = config_path.read_text()
""",
            "pep": None
        }
        
        self.resource_management = {
            "name": "Context Managers",
            "description": "Use with for resource management",
            "example": """
with open('file.txt', 'r') as f:
    content = f.read()
    
# File is automatically closed after the block
""",
            "pep": None
        }
        
        self.debugging = {
            "name": "breakpoint()",
            "description": "Python 3.7+ modern debugger hook",
            "example": """
def complex_function(data):
    # When something goes wrong
    if unexpected_condition:
        breakpoint()  # Drops into the debugger
    # Continue processing
""",
            "pep": None
        }
        
        self.syntax_features = {
            "enumerate": {
                "name": "enumerate()",
                "description": "Get index with item in loops",
                "example": """
fruits = ['apple', 'banana', 'cherry']
for i, fruit in enumerate(fruits):
    print(f"{i+1}. {fruit}")
"""
            },
            "comprehensions": {
                "name": "Comprehensions",
                "description": "Concise creation of lists, dicts, and sets",
                "example": """
# List comprehension
squares = [x**2 for x in range(10)]

# Dictionary comprehension
name_to_age = {person.name: person.age for person in people}

# Set comprehension
unique_letters = {char.lower() for char in text}
"""
            },
            "walrus": {
                "name": "Walrus Operator (:=)",
                "description": "Assignment expressions for cleaner code",
                "example": """
# Without walrus operator
chunk = stream.read(1024)
if chunk:
    process(chunk)
    
# With walrus operator
if (chunk := stream.read(1024)):
    process(chunk)
"""
            }
        }
        
        self.collections = {
            "name": "collections.abc",
            "description": "When defining custom collections",
            "example": """
from collections.abc import Sequence

class ReadOnlyList(Sequence):
    def __init__(self, data):
        self._data = list(data)
        
    def __getitem__(self, index):
        return self._data[index]
        
    def __len__(self):
        return len(self._data)
"""
        }
        
        self.datetime = {
            "name": "Timezone-aware datetime",
            "description": "Use for unambiguous timestamps",
            "example": """
from datetime import datetime, timezone

# Create timezone-aware datetime
now = datetime.now(timezone.utc)

# Convert to a specific timezone
import zoneinfo
local_time = now.astimezone(zoneinfo.ZoneInfo('America/New_York'))
"""
        }
        
        # Referenced PEPs
        self.referenced_peps = {
            "8": "Style Guide for Python Code",
            "20": "The Zen of Python",
            "257": "Docstring Conventions",
            "484": "Type Hints",
            "557": "Data Classes",
            "695": "Type Parameter Syntax",
            "696": "Type Defaults for Type Parameters (Python 3.13+)",
            "719": "Python 3.13 Release Schedule",
            "3129": "Class Decorators"
        }
    
    def get_peps(self):
        """Return all referenced PEPs with descriptions"""
        return self.referenced_peps
    
    def get_examples(self):
        """Return examples of all modern syntax features"""
        examples = {}
        
        # String formatting
        examples["f_strings"] = self.string_formatting["example"]
        
        # Type system
        for key, value in self.type_system.items():
            examples[key] = value["example"]
        
        # File system
        examples["pathlib"] = self.file_system["example"]
        
        # Resource management
        examples["context_managers"] = self.resource_management["example"]
        
        # Debugging
        examples["breakpoint"] = self.debugging["example"]
        
        # Syntax features
        for key, value in self.syntax_features.items():
            examples[key] = value["example"]
        
        # Collections
        examples["collections_abc"] = self.collections["example"]
        
        # Datetime
        examples["timezone_datetime"] = self.datetime["example"]
        
        return examples
    
    def __str__(self):
        """String representation of Modern Python Syntax"""
        return f"{self.name} (Python {self.min_python_version}, preferably {self.preferred_version})"


# Example usage
if __name__ == "__main__":
    syntax = ModernPythonSyntax()
    
    print(f"ðŸ {syntax}")
    
    print("\nðŸ”¤ String Formatting:")
    print(f"- {syntax.string_formatting['name']}: {syntax.string_formatting['description']}")
    print("```python")
    print(syntax.string_formatting['example'])
    print("```")
    
    print("\nðŸ“ Type System:")
    for key, value in syntax.type_system.items():
        print(f"- {value['name']}: {value['description']}")
        if value['pep']:
            print(f"  (PEP {value['pep']})")
        print("```python")
        print(value['example'])
        print("```")
    
    print("\nðŸ“‚ File System:")
    print(f"- {syntax.file_system['name']}: {syntax.file_system['description']}")
    print("```python")
    print(syntax.file_system['example'])
    print("```")
    
    print("\nðŸ”„ Resource Management:")
    print(f"- {syntax.resource_management['name']}: {syntax.resource_management['description']}")
    print("```python")
    print(syntax.resource_management['example'])
    print("```")
    
    print("\nðŸž Debugging:")
    print(f"- {syntax.debugging['name']}: {syntax.debugging['description']}")
    print("```python")
    print(syntax.debugging['example'])
    print("```")
    
    print("\nâš¡ Syntax Features:")
    for key, value in syntax.syntax_features.items():
        print(f"- {value['name']}: {value['description']}")
        print("```python")
        print(value['example'])
        print("```")
    
    print("\nðŸ“š Collections:")
    print(f"- {syntax.collections['name']}: {syntax.collections['description']}")
    print("```python")
    print(syntax.collections['example'])
    print("```")
    
    print("\nðŸ•’ Date and Time:")
    print(f"- {syntax.datetime['name']}: {syntax.datetime['description']}")
    print("```python")
    print(syntax.datetime['example'])
    print("```")
    
    print("\nðŸ“‘ Referenced PEPs:")
    for pep, description in syntax.get_peps().items():
        print(f"- PEP {pep}: {description}")./main.py
#!/usr/bin/env python3
"""
Python Best Practices - Integrated Demo Application

This module serves as the main entry point for demonstrating how all
the individual best practice modules work together to form a complete
application. It orchestrates the various components while preserving
their educational value.
"""

import logging
import os
import sys
import argparse
from pathlib import Path

# Import our best practice modules
from dry import DRY
from solid import SOLID
from environment import EnvironmentManagement
from observability import LoggingObservabilityStandards
from modern import ModernPythonSyntax
from validation import DataValidationAndConfiguration
from tasks import BackgroundTasksAndConcurrency
from fast_api_best_practice import FastAPIBestPractices
from git_branching import GitBranching


class IntegratedDemoApplication:
    """
    Demonstrates how all best practice modules work together
    in a cohesive application architecture.
    """
    
    def __init__(self):
        """Initialize the integrated demo application."""
        self.app_name = "PyBestPractices"
        
        # Setup structured logging first (foundation for all other components)
        self.logging_standards = LoggingObservabilityStandards()
        self.logger = self.logging_standards.create_basic_jsonl_logger()
        self.logger.info("Initializing integrated demo application", app_name=self.app_name)
        
        # Initialize environment
        self.env_manager = EnvironmentManagement()
        self.logger.info("Environment manager initialized", branching_strategy=str(self.env_manager.branching_strategy))
        
        # Initialize git branching utilities
        self.git_manager = GitBranching()
        
        # Initialize data validation system
        self.validation_system = DataValidationAndConfiguration()
        
        # Initialize background task system
        self.task_system = BackgroundTasksAndConcurrency()
        
        # Core principles (educational components)
        self.dry_principle = DRY()
        self.solid_principles = SOLID()
        self.modern_syntax = ModernPythonSyntax()
        
        # The API application (primary interface)
        self.api = FastAPIBestPractices()
        
        self.logger.info("All components initialized successfully")
    
    def run_standalone_demo(self):
        """Run a demonstration that shows all components working together."""
        print("\n" + "=" * 80)
        print(f"ðŸš€ {self.app_name} - INTEGRATED BEST PRACTICES DEMO")
        print("=" * 80)
        
        # Show core principles in action
        print("\nðŸ“š Core Programming Principles:")
        print(f"â€¢ {self.dry_principle}")
        print(f"â€¢ {self.solid_principles}")
        
        # Demonstrate environment setup
        print("\nðŸ› ï¸ Project Environment:")
        project_name = "example_project"
        print(f"â€¢ Creating pyproject.toml for {project_name}")
        pyproject_content = self.env_manager.setup_pyproject_toml(project_name)
        print(f"â€¢ Setting up virtual environment: {self.env_manager.setup_venv_command()}")
        
        # Demonstrate git workflow
        print("\nðŸ“‹ Git Workflow:")
        feature_name = "user-authentication"
        feature_branch_cmd = self.git_manager.create_feature_branch(feature_name)
        print(f"â€¢ Feature branch command: {feature_branch_cmd}")
        
        # Demonstrate data validation
        print("\nâœ… Data Validation:")
        settings_example = self.validation_system.generate_settings_example()
        print(f"â€¢ Generated settings class with validation")
        
        # Demonstrate background tasks
        print("\nðŸ”„ Background Tasks:")
        celery_config = self.task_system.get_celery_task_decorator("critical")
        print(f"â€¢ Critical task configuration prepared")
        
        # Start the API (last step)
        print("\nðŸŒ API Service:")
        print("â€¢ Starting FastAPI application (press Ctrl+C to exit)")
        
        # Run the actual API server
        self.api.run_demo()
    
    def parse_args(self):
        """Parse command line arguments."""
        parser = argparse.ArgumentParser(description="Python Best Practices Integrated Demo")
        parser.add_argument("--component", type=str, choices=[
            "all", "api", "tasks", "logging", "validation", "environment", 
            "git", "solid", "dry", "modern"
        ], default="all", help="Specific component to demonstrate")
        
        return parser.parse_args()
    
    def run(self):
        """Run the demo based on command line arguments."""
        args = self.parse_args()
        
        if args.component == "all":
            self.run_standalone_demo()
        elif args.component == "api":
            self.api.run_demo()
        elif args.component == "tasks":
            print(f"ðŸ“‹ {self.task_system.name} Demo:")
            print(self.task_system.get_celery_example())
        elif args.component == "logging":
            print(f"ðŸ“‹ {self.logging_standards.name} Demo:")
            print(self.logging_standards.get_structlog_implementation())
        elif args.component == "validation":
            print(f"ðŸ“‹ {self.validation_system.name} Demo:")
            for principle in self.validation_system.core_principles:
                print(f"\nâ€¢ {principle.name}: {principle.description}")
        elif args.component == "environment":
            print(f"ðŸ“‹ {self.env_manager.name} Demo:")
            print(self.env_manager.setup_pyproject_toml("demo_project"))
        elif args.component == "git":
            print(f"ðŸ“‹ Git Branching Strategy Demo:")
            print(self.git_manager.create_feature_branch("example-feature"))
        elif args.component == "solid":
            print(f"ðŸ“‹ SOLID Principles Demo:")
            for letter in "SOLID":
                principle = self.solid_principles.get_principle(letter)
                print(f"\nâ€¢ {principle['name']} Principle: {principle['description']}")
        elif args.component == "dry":
            print(f"ðŸ“‹ {self.dry_principle} Demo:")
            examples = self.dry_principle.get_examples()
            print("\nNon-DRY Code Example:")
            print(examples["non_dry"])
            print("\nDRY Code Example:")
            print(examples["dry"])
        elif args.component == "modern":
            print(f"ðŸ“‹ {self.modern_syntax.name} Demo:")
            print(f"Recommended Python Version: {self.modern_syntax.preferred_version}")


if __name__ == "__main__":
    app = IntegratedDemoApplication()
    app.run() 